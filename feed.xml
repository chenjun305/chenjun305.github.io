<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="cn"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://chenjun305.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://chenjun305.github.io/" rel="alternate" type="text/html" hreflang="cn"/><updated>2023-12-13T05:20:55+00:00</updated><id>https://chenjun305.github.io/feed.xml</id><title type="html">blank</title><subtitle>chenjun personal site and blog </subtitle><entry><title type="html">Linux系统性能分析神器BPF</title><link href="https://chenjun305.github.io/blog/2023/bpf/" rel="alternate" type="text/html" title="Linux系统性能分析神器BPF"/><published>2023-09-01T00:00:00+00:00</published><updated>2023-09-01T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/bpf</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/bpf/"><![CDATA[<h2 id="bpf是什么">BPF是什么？</h2> <ul> <li>BPF是Berkeley packet Filter的缩写，诞生于1992年，最早用于提升网络包过滤工具的性能。</li> <li>2013年，Alexei Starovoitov重新实现了BPF，经过他和Daniel Borkmann的共同完善，在2014年正式并入Linux内核主线。</li> <li>BPF提供了一种在各种内核事件和应用程序事件发生时运行一小段程序的机制。这就使得内核变得可编程。允许用户定制和控制他们的系统。</li> <li>BPF由指令集，存储对象和辅助函数等几部分组成。由于它采用了虚拟指令集规范，因此可将它视作一种虚拟机实现，这些指令由Linux内核的BPF运行时模块执行。（可类比Java虚拟机）</li> <li>应用领域：网络，可观测性，安全。</li> </ul> <h2 id="bcc-bpftrace">BCC, bpftrace</h2> <p>由于直接通过BPF指令编写BPF程序是非常繁琐的，因此社区开发了可以提供高级语言编程的BPF前端。其中BCC和bpftrace都是属于Github上的一个名为IO Visor的Linux基金会项目。</p> <ul> <li><a href="https://github.com/iovisor/bcc">BCC</a>（BPF Compiler Collection）是最早用于开发BPF跟踪程序的高级框架，它提供了一个编写内核BPF程序的C语言环境，同时还提供了其他高级语言(如python,lua,C++)环境来实现用户端接口。</li> <li><a href="https://github.com/iovisor/bpftrace">bpftrace</a>提供了专门用于创建BPF工具的高级语言支持。且bpftrace的源代码非常简洁。</li> <li>BCC和bpftrace具有互补性，bpftrace在编写功能强大的单行程序，短小的脚本方面甚为理想；BCC则更适合开发复杂的脚本和作为后台进程使用，它还可以调用其他库的支持。</li> <li>libbcc和libbpf库提供了使用BPF程序对事件进行观测的库函数。</li> <li>另外，还有一个叫<a href="https://github.com/iovisor/ply">ply</a>的BPF前端，目前处于开发阶段。它的设计目标是尽可能轻量化并且依赖最小化，因此尤其适合在嵌入式Linux环境下使用。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-bcc-bpftrace-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-bcc-bpftrace-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-bcc-bpftrace-1400.webp"/> <img src="/assets/img/bpf-bcc-bpftrace.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> BCC, bpftrace 和 BPF </div> <h2 id="bpf跟踪的能见度">BPF跟踪的能见度</h2> <p>BPF跟踪可以在整个软件栈范围内提供能见度，在生产环境中可以立刻部署BPF程序，不需要重启系统，也不需要以特殊方式重启应用软件。这有点像医学检查使用的X光影像。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-tools-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-tools-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-tools-1400.webp"/> <img src="/assets/img/bpf-tools.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> BPF跟踪的能见度 </div> <h2 id="图解bpf">图解BPF</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-tracing-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-tracing-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-tracing-1400.webp"/> <img src="/assets/img/bpf-tracing.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> BPF跟踪技术 </div> <h3 id="早期的经典bpf">早期的经典BPF</h3> <p>BPF最初是为BSD操作系统开发的，其工作方式十分有趣：用户使用BPF虚拟机的指令集定义过滤器表达式，然后传递给内核，由解释器执行。 这使得包过滤可以在内核中直接进行，避免了向用户态进程复制每个数据包，从而提升了数据包过滤的性能，著名的网络抓包工具tcpdump就是这样工作的。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-tcpdump-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-tcpdump-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-tcpdump-1400.webp"/> <img src="/assets/img/bpf-tcpdump.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> tcpdump与BPF </div> <p>最初的BPF现在被成为经典BPF，它是一个功能有限的虚拟机。它由两个寄存器，一个由16个内存槽位组成的临时存储区域和一个程序计数器。经典BPF于1997年进入Linux内核版本2.1.75</p> <h3 id="现在的扩展版bpf">现在的扩展版BPF</h3> <p>扩展版BPF增加了更多寄存器，字长从32位增至64位，创建了灵活的BPF映射型存储，并允许调用一些受限制的内核功能。同时，BPF被设计成可以使用即时编译（JIT），机器指令和寄存器可以一对一映射。支持的事件类型也更加丰富,除了网络数据包，还包括kprobes(内核函数)、uprobes(用户态函数)、tracepoints（跟踪点），USDT（用户态标记）， PMC，perf_events等。</p> <p>BPF运行时（runtime）的各模块架构如下图所示，它展示了BPF指令如何通过BPF验证器验证，然后通过JIT编译器编译成机器码,最后由BPF虚拟机执行。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-runtime-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-runtime-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-runtime-1400.webp"/> <img src="/assets/img/bpf-runtime.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> BPF运行时的内部结构 </div> <ul> <li>为什么性能工具需要BPF技术</li> </ul> <p>BPF与众不同之处在于，它同时具备高效率和生产环境安全性的特点，并且它已经被内置在内核中。 下图对比了“用直方图的形式展示磁盘I/O的尺寸分布”的处理过程。使用BPF避免了将事件复制到用户空间并再次对其处理的成本。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bpf-efficiency-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bpf-efficiency-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bpf-efficiency-1400.webp"/> <img src="/assets/img/bpf-efficiency.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 使用BPF之前和之后生成直方图过程的对比。 </div> <h2 id="bpf跟踪的事件源">BPF跟踪的事件源</h2> <ul> <li>动态插桩 kprobes <ul> <li>kprobes 提供了针对内核的动态插桩支持。2004年，kprobes正式加入内核2.6.9版本。</li> <li>kprobes 可以对任何内核函数进行插桩，它可以实时在生产环境系统启用，不需要重启系统，也不需要以特殊方式重启内核。</li> <li>kprobes 技术还有另外一个接口，即kretprobes, 用来对内核函数返回时进行插桩以获取返回值。</li> <li>使用举例：下面这个bpftrace单行程序通过匹配<code class="language-plaintext highlighter-rouge">vfs_</code>开头的函数，统计了所有VFS函数的调用次数。</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo bpftrace -e 'kprobe:vfs_* { @[probe] = count() }'
@[kprobe:vfs_statx]: 28
@[kprobe:vfs_write]: 49
@[kprobe:vfs_getattr_nosec]: 60
@[kprobe:vfs_read]: 143
@[kprobe:vfs_open]: 168
</code></pre></div> </div> </li> <li>动态插桩uprobes <ul> <li>uprobes 提供了用户态程序的动态插桩。于2012年7月被合并到Linux 3.5内核中。</li> <li>uprobes 可以在用户态程序的以下位置插桩：函数入口，特定便宜处，以及函数返回处。</li> <li>uprobes 是基于文件的，当一个可执行文件的一个函数被跟踪时，所有使用到这个文件的进程都会被插桩。</li> <li>使用举例：下面的bpftrace单行程序对readline()进行插桩</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bpftrace -e 'uprobe:/bin/bash:readline { @ = count() }'
Attaching 1 probe... 
</code></pre></div> </div> </li> <li>静态插桩tracepoint <ul> <li>跟踪点（tracepoint）可以用来对内核进行静态插桩。内核开发者在内核函数的特定逻辑位置处，有意放置了这些插桩点；</li> <li>该技术正式出现在2009年发布的Linux 2.6.32内核中。</li> <li>跟踪点的格式是“子系统：事件名”，例如：<code class="language-plaintext highlighter-rouge">kmem:kmalloc</code></li> </ul> </li> <li>静态插桩USDT <ul> <li>用户态预定义静态跟踪（user-level statically defined tracing, USDT）提供了一个用户空间版的跟踪点机制。</li> </ul> </li> <li>动态USDT</li> <li>PMC性能监控计数器 <ul> <li>performance monitoring counter, 指的是：处理器上的硬件可编程计数器。</li> <li>只有通过PMC才能测量CPU指令执行的效率，CPU缓冲命中率，内存/数据互联和设备总线利用率，以及阻塞的指令周期等。</li> </ul> </li> <li>perf_events <ul> <li>perf_events是<code class="language-plaintext highlighter-rouge">perf</code>命令所依赖的采样和跟踪机制，它于2009年被加入Linux 2.6.31版本。</li> </ul> </li> </ul> <h2 id="安装">安装</h2> <ul> <li>安装bcc</li> </ul> <p>以ubuntu系统为例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt-get install bpfcc-tools linux-headers-$(uname -r)
</code></pre></div></div> <p>这会把BCC工具安装到/sbin目录下，并带有<code class="language-plaintext highlighter-rouge">-bpfcc</code>后缀。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls /sbin/*-bpfcc
</code></pre></div></div> <ul> <li>安装bpftrace</li> </ul> <p>以ubuntu系统为例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo apt-get install bpftrace

$ which bpftrace
/usr/bin/bpftrace
</code></pre></div></div> <h2 id="性能分析方法论">性能分析方法论</h2> <p>方法论是一个可以遵循的过程：它指导从哪里开始，中间步骤有哪些和到哪里结束。</p> <h3 id="业务负载画像">业务负载画像</h3> <p>业务负载画像的目的是理解实际运行的业务负载。“消除不必要的工作”是在性能优化结果中收益最显著的一种。通过研究业务负载的构成就可以找到这样的优化点。</p> <p>推荐步骤如下：</p> <ol> <li>负载是谁产生的？（比如，进程ID，用户ID，IP地址）</li> <li>负载为什么会产生？</li> <li>负载的组成是什么？</li> <li>负载怎样随着事件发生变化？</li> </ol> <h3 id="下钻分析">下钻分析</h3> <p>下钻分析的工作过程是从一个指标开始，然后将这个指标拆分成多个组成部分，再将最大的组件进一步拆分为更小的组件，不断重复这个过程直到定位出一个或多个根因。</p> <p>推荐步骤如下：</p> <ol> <li>从业务最高层级开始分析</li> <li>检查下一个层级的细节</li> <li>挑出最感兴趣的部分或线索</li> <li>如果问题还没有解决，跳转至第2步</li> </ol> <h3 id="use方法论">USE方法论</h3> <p>USE方法论用来对资源的使用情况进行分析，针对每一个资源，分别去检查：</p> <ol> <li>使用率</li> <li>饱和度</li> <li>错误</li> </ol> <p>这些资源包括CPU，内存，磁盘，网络等。</p> <h3 id="检查清单法">检查清单法</h3> <p>检查清单法可以列出一系列工具和指标，用于对照运行和检查。 这个方法论适用于指导公司各个层次的工程师实施操作，将个人技能应用于更广的范围内。</p> <h4 id="linux-60秒分析">Linux 60秒分析</h4> <ol> <li><code class="language-plaintext highlighter-rouge">uptime</code> 快速检查平均负载</li> <li><code class="language-plaintext highlighter-rouge">dmesg | tail</code> 显示过去10条系统日志，寻找可能导致性能问题的错误</li> <li><code class="language-plaintext highlighter-rouge">vmstat 1</code> 显示CPU，内存，IO等系统指标</li> <li><code class="language-plaintext highlighter-rouge">mpstat -P All 1</code> 将每个CPU分解到各个状态下的事件打印出来</li> <li><code class="language-plaintext highlighter-rouge">pidstat 1</code> 按每个进程展示CPU的使用情况</li> <li><code class="language-plaintext highlighter-rouge">iostat -xz 1</code> 显示存储设备的IO指标</li> <li><code class="language-plaintext highlighter-rouge">free -m</code> 显示以MB为单位的可用内存</li> <li><code class="language-plaintext highlighter-rouge">sar -n DEV 1</code> 查看网络设备指标</li> <li><code class="language-plaintext highlighter-rouge">sar -n TCP, ETCP 1</code> 查看TCP指标和TCP错误信息（比如retrans/s 每秒TCP重传的数量）</li> <li><code class="language-plaintext highlighter-rouge">top</code> 对相关结果进行二次确认，浏览系统和进程的摘要信息。</li> </ol> <h4 id="bcc工具检查清单">BCC工具检查清单</h4> <ol> <li><code class="language-plaintext highlighter-rouge">execsnoop</code> 通过跟踪每次<code class="language-plaintext highlighter-rouge">execve</code>系统调用，监控系统新进程的创建</li> <li><code class="language-plaintext highlighter-rouge">opensnoop</code> 通过跟踪每次<code class="language-plaintext highlighter-rouge">open</code>系统调用，跟踪进程打开文件信息</li> <li><code class="language-plaintext highlighter-rouge">ext4slower</code> 跟踪ext4文件系统常见操作，把耗时超过某个阈值的操作打印出来</li> <li><code class="language-plaintext highlighter-rouge">biolatency</code> 跟踪磁盘IO延迟, 并且以直方图显示</li> <li><code class="language-plaintext highlighter-rouge">biosnoop</code> 将每一次磁盘IO请求打印出来，包含调用进程，延迟之类的细节信息</li> <li><code class="language-plaintext highlighter-rouge">cachestat</code> 显示文件系统缓冲的统计信息，可发现缓存命中率较低的问题</li> <li><code class="language-plaintext highlighter-rouge">tcpconnect</code> 跟踪每次主动的TCP连接建立，寻找不寻常的连接请求</li> <li><code class="language-plaintext highlighter-rouge">tcpaccept</code> 跟踪每次被动的TCP连接建立时</li> <li><code class="language-plaintext highlighter-rouge">tcpretrans</code> 跟踪TCP重传数据包，TCP重传会导致延迟和吞吐量方面的问题</li> <li><code class="language-plaintext highlighter-rouge">runqlat</code> 对线程等待CPU运行的事件进行统计，并打印为一个直方图</li> <li><code class="language-plaintext highlighter-rouge">profile</code> CPU剖析器，用来理解哪些代码路径消耗了CPU资源</li> </ol>]]></content><author><name></name></author><category term="programming"/><category term="Linux"/><summary type="html"><![CDATA[BPF是什么？ BPF是Berkeley packet Filter的缩写，诞生于1992年，最早用于提升网络包过滤工具的性能。 2013年，Alexei Starovoitov重新实现了BPF，经过他和Daniel Borkmann的共同完善，在2014年正式并入Linux内核主线。 BPF提供了一种在各种内核事件和应用程序事件发生时运行一小段程序的机制。这就使得内核变得可编程。允许用户定制和控制他们的系统。 BPF由指令集，存储对象和辅助函数等几部分组成。由于它采用了虚拟指令集规范，因此可将它视作一种虚拟机实现，这些指令由Linux内核的BPF运行时模块执行。（可类比Java虚拟机） 应用领域：网络，可观测性，安全。]]></summary></entry><entry><title type="html">Salesforce元数据驱动的多租户架构</title><link href="https://chenjun305.github.io/blog/2023/multi-tenant-architecture/" rel="alternate" type="text/html" title="Salesforce元数据驱动的多租户架构"/><published>2023-08-01T00:00:00+00:00</published><updated>2023-08-01T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/multi-tenant-architecture</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/multi-tenant-architecture/"><![CDATA[<p>近段时间，我主要在从事CRM系统的架构工作，自然对业界相关的技术进行了一些调研，Salesforce是CRM领域的标杆和鼻祖，也是全球企业信息服务界的龙头。本文记录我调研整理的Salesforce的后端技术架构相关信息。</p> <h3 id="salesforce简介">Salesforce简介</h3> <h4 id="salesforce发展史">Salesforce发展史</h4> <p>Salesforce的创立者叫Marc Benioff。1999年时，他27岁，为当时美国一家软件巨头Oracle最年轻的高级副总裁。20世纪90年代中后期，像Oracle这样的企业售卖软件按Licence（对付费用户进行授权，以正常使用软件的完整功能）收费，并由软件厂商去部署安装。Marc任Oracle高级副总裁期间，形成了将CRM等通用软件通过互联网部署的想法：用云端模式交付，使用者则像“交水电费那样为自己的软件付费。但他的想法并没有得到前东家的认可，于是决定创业，1999年3月，Salesforce诞生。</p> <ul> <li>1999年，由前甲骨文高管Marc Benioff创立</li> <li>2001年，推出了第一款SaaS应用CRM，受到热议</li> <li>2004年，纽交所上市，市值10亿美元，股票代码CRM</li> <li>2005年，推出了名为“AppExchange”的程序商店</li> <li>2007年，推出了PaaS平台Force.com，让用户更方便地开发在线应用</li> <li>2009年，推出了”Service Cloud”在线客户服务应用</li> <li>2012年，推出“Marketing Cloud”</li> <li>2015年，构建电商云</li> <li>2016年，推出了AI产品Einstein，将AI技术引入到SaaS服务中</li> <li>2019年，收购数据分析平台Tableau</li> <li>2021年，收购企业通讯SaaS软件Slack，补强协同办公功能</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-history-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-history-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-history-1400.webp"/> <img src="/assets/img/salesforce-history.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce发展史中的重要节点 </div> <h4 id="全球crm市场份额">全球CRM市场份额</h4> <p>Salesforce近年来在 CRM 行业的市场份额稳居第一，2021 年市占率为 23.8%，SAP 和 Microsoft 位列 第二和第三，市占率均不及 5.5%，与 Salesforce 的差距较大</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/crm-share-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/crm-share-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/crm-share-1400.webp"/> <img src="/assets/img/crm-share.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 全球CRM市场份额 </div> <h4 id="salesforce付费模式">Salesforce付费模式</h4> <p>Salesforce采用的是订阅付费模式，用户的续费率至关重要。如果Salesforce的产品不能为企业创造真正的价值，那么第二期的续费将得不到保证。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sales-cloud-pricing-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sales-cloud-pricing-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sales-cloud-pricing-1400.webp"/> <img src="/assets/img/sales-cloud-pricing.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce订阅付费模式 </div> <p>同时其订阅费用采用阶梯定价的收费模式，产品能力是吸引客户提升付费等级的关键因素。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/sales-cloud-pricing2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/sales-cloud-pricing2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/sales-cloud-pricing2-1400.webp"/> <img src="/assets/img/sales-cloud-pricing2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce的阶梯定价收费模式 </div> <h4 id="salesforce围绕crm的4朵云">Salesforce围绕CRM的4朵云</h4> <ul> <li>销售云（sales cloud) <ul> <li>服务于销售部门，销售流程的规范化和提升销售效率。销售线索、潜在客户的获取， 销售流程的自动化推进，销售过程跟踪和共享。</li> </ul> </li> <li>服务云（service cloud） <ul> <li>服务于客服部门，高效互动，提升客服效率。Salesforce呼叫中心提供多渠道、全时段的客户服务支持，客户行为记录以提供个性化服务。</li> </ul> </li> <li>营销云（marketing cloud） <ul> <li>服务于市场部门，营销策略的管理和销售数据传递。用户画像、定制化的营销方式、社交媒体营销、数字化营销、跨渠道营销。</li> </ul> </li> <li>商业云（commerce cloud） <ul> <li>提供商业变现的渠道。企业在线上进行直接的销售，提供交易撮合、订单管理等商业服务，提升消费体验。</li> </ul> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-income-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-income-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-income-1400.webp"/> <img src="/assets/img/salesforce-income.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce公司收入结构 </div> <h4 id="salesforce产品矩阵">Salesforce产品矩阵</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-product-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-product-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-product-1400.webp"/> <img src="/assets/img/salesforce-product.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce产品矩阵 </div> <h3 id="技术架构">技术架构</h3> <p>企业运维架构经历了从On-Premises(自建机房) -&gt; IaaS(基础设施即服务) -&gt; PaaS（平台即服务） -&gt; SaaS（软件即服务）的演进，越往后，企业所要关注的点越少。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/platform-architecture1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/platform-architecture1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/platform-architecture1-1400.webp"/> <img src="/assets/img/platform-architecture1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 企业运维架构的演进 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/platform-architecture2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/platform-architecture2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/platform-architecture2-1400.webp"/> <img src="/assets/img/platform-architecture2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 主要代表平台 </div> <p>Salesforce是SaaS和PaaS思想的首推者。<br/> 构成其平台能力的核心主要是其元数据驱动的多租户架构。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-architecture1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-architecture1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-architecture1-1400.webp"/> <img src="/assets/img/salesforce-architecture1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce的技术架构 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-core-architecture-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-core-architecture-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-core-architecture-1400.webp"/> <img src="/assets/img/salesforce-core-architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce技术架构的核心 </div> <h3 id="多租户架构">多租户架构</h3> <p>提到多租户，我们可以首先可以联想到现实生活中的多租户的概念。<br/> 比如我们公司租了一栋大楼里的一间房，我们和这栋大楼的其他租户是共享这栋大楼的基础设施，比如电力供应，自来水，电梯，物业安保等，但我们租的那间房只有我们公司的员工能进入和使用，其他租户的员工无权进入。我们要缴纳租金，我们使用的水电费等。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/building-tenant-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/building-tenant-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/building-tenant-1400.webp"/> <img src="/assets/img/building-tenant.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 现实生活中大楼里的租户 </div> <p>同样的，软件世界里的多租户，也是类似的概念，同一个SaaS平台的租户共享硬件设备和存储等基础设施。同一个租户内的不同用户间共享数据，不同的租户间通过软件进行隔离。 还有需要注意的是，这里的多租户架构和传统的软件销售On-Premises方式，软件供应商给每个客户安装一套系统不同，这里的多租户架构是所有客户共享一套软件基础设施。</p> <ul> <li>概念 <ul> <li>多租户指得就是一个单独的软件实例可以为多个组织服务。</li> <li>设计上对数据和配置信息进行虚拟分区，需要对数据库结构进行特殊的设计。</li> <li>安全和隔离性要有所保障。</li> </ul> </li> <li>多租户和多用户的区别 <ul> <li>多用户的关键点在于不同的用户拥有不同的访问权限，但多个用户共享相同的业务数据；</li> <li>多租户间的业务数据是隔离的。</li> </ul> </li> <li>多租户和虚拟化的区别 <ul> <li>作用的层次不同，虚拟化是虚拟出一个操作系统，多租户是虚拟出一个应用实例。</li> </ul> </li> </ul> <h4 id="多租户架构的优缺点">多租户架构的优缺点</h4> <ul> <li>优点 <ul> <li>经济</li> <li>易于更新和开发</li> <li>管理方便</li> <li>One version, Bugs fixed for everyone</li> </ul> </li> <li>缺点 <ul> <li>更复杂</li> <li>不够安全/租户间隔离性</li> </ul> </li> </ul> <h4 id="多租户架构的几种模型">多租户架构的几种模型</h4> <p>区别主要在于采用不同的数据库模式（Database Schema)</p> <ul> <li>私有表 <ul> <li>机制：为每个租户的自定义数据创建一个新表</li> <li>优点：简单</li> <li>缺点：需要DDL操作，低整合度</li> </ul> </li> <li>扩展表 <ul> <li>机制：一个扩展表会被多个租户共享</li> <li>优点：高整合度，少DDL操作</li> <li>缺点：有点复杂</li> </ul> </li> <li>通用表 <ul> <li>机制：通过一个通用表来存放所有自定义信息</li> <li>优点：极高整合度，无DDL操作</li> <li>缺点：实现难度高</li> </ul> </li> </ul> <h4 id="salesforce的多租户架构">Salesforce的多租户架构</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-multi-tenant-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-multi-tenant-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-multi-tenant-1400.webp"/> <img src="/assets/img/salesforce-multi-tenant.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce的多租户架构 </div> <h3 id="元数据驱动metadata-driven">元数据驱动(Metadata Driven)</h3> <h4 id="什么是元数据">什么是元数据？</h4> <ul> <li>业务数据 <ul> <li>指的是客户，联系人，业务机会，合同等跟业务发生关联的数据。</li> </ul> </li> <li>元数据 <ul> <li>关于数据的数据</li> <li>指的是对象，字段，页面布局，验证规则，工作流等这类定义应用本身的数据。</li> <li>也被称为UDD （Universal Data Dictionary）通用数据字典</li> </ul> </li> </ul> <h4 id="元数据驱动的实现原理">元数据驱动的实现原理</h4> <p>理论上来说，我们只需要3张表就可以实现所有租户的所有需求。<br/> 不同租户通过唯一的OrgID隔离，所有数据访问操作都要带OrgID参数，value0~value500存储对象的不同属性。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/metadata1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/metadata1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/metadata1-1400.webp"/> <img src="/assets/img/metadata1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 元数据驱动的实现原理 </div> <h4 id="salesforce数据层">Salesforce数据层</h4> <ul> <li>元数据表（Metadata Tables）</li> <li>数据表（Data Tables）</li> <li>索引表（Specialized Pivot tables）</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-data-layer-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-data-layer-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-data-layer-1400.webp"/> <img src="/assets/img/salesforce-data-layer.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce数据层 </div> <h5 id="data表">Data表</h5> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-data-table-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-data-table-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-data-table-1400.webp"/> <img src="/assets/img/salesforce-data-table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Data表 </div> <p>大多数结构化数据都以可变字符串形式存储在value0~500的列里。（包括数字，日期等），但无法利用底层数据库索引的能力快速查询和排序？怎么解决呢？</p> <h5 id="indexes表">indexes表</h5> <p>解决方案是把数据拷贝出数据表并转换成原始的的数据类型，并存储到Indexes索引表列内，<br/> Indexes 表的底层索引是标准的，采用非唯一性的数据库索引。<br/> 查询先查indexes表，再查data表获取数据。<br/> indexes表的字段定义如下：</p> <ul> <li>OrgID：其所归属的应用对象所归属的租户OrgID</li> <li>ObjID：字段所属应用对象唯一标识</li> <li>FieldNum：对象字段存储位置</li> <li>ObjInstanceGUID：对象实例唯一标识</li> <li>StringValue：强类型的字符串列</li> <li>NumValue：强类型的数字列</li> <li>DateValue：强类型的日期列</li> </ul> <h5 id="unique-indexes表">Unique Indexes表</h5> <p>这个表非常类似于 Indexes 表，不过 Unique indexes采用底层原生的数据库索引来强制唯一性校验。</p> <ul> <li>UniqueStringValue：唯一的字符串列</li> <li>UniqueNumValue：唯一的数字列</li> <li>UniqueDateValue：唯一的日期列</li> <li>其他字段定义请参考 Indexes 透视表</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-indexes-table-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-indexes-table-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-indexes-table-1400.webp"/> <img src="/assets/img/salesforce-indexes-table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-unique-indexes-table-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-unique-indexes-table-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-unique-indexes-table-1400.webp"/> <img src="/assets/img/salesforce-unique-indexes-table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> indexes表和unique indexes表 </div> <h5 id="relationship索引表">Relationship索引表</h5> <ul> <li>字段 <ul> <li>OrgID:租户ID</li> <li>ObjID:子对象的对象标识</li> <li>GUID：子对象实例的唯一表识</li> <li>RelationID：子对象内关系字段定义的标识</li> <li>TargetObjInstanceID：父对象实例的唯一标识</li> </ul> </li> <li>定义了两个底层数据库复合索引存储引用关系 <ul> <li>第一个索引字段：OrgID + GUID，用于从子对象到父对象的关联查询。</li> <li>第二个索引字段：OrgID + ObjID + RelationID + TargetObjInstanceID，用于父对象到子对象的关联查询。</li> </ul> <h5 id="如何支撑多租户巨大数据量">如何支撑多租户巨大数据量？</h5> </li> <li>Data Partitioning数据分区 <ul> <li>所有的 Force.com 的数据，元数据，透视表结构，包含底层数据库索引，都是通过对 OrgID 进行物理分区的，采用的是原生的数据库分区机制。</li> <li>数据分区是数据库系统提供的被验证过的技术，用以物理划分较大的逻辑数据结构到较小的可以管理的区块中。</li> </ul> </li> </ul> <h5 id="无感的对象结构变更no-ddl">无感的对象结构变更No DDL</h5> <ul> <li>在元数据驱动的数据架构中，所有的 DDL 语言操作对应的使元数据层的元数据的记录的更新，不涉及数据库物理结构的更新</li> <li>当用户修改了一个表字段列的数据结构，从一种数据类型改成另外一种不同存储格式的数据类型时候，系统会重新分派一个新的弹性列给到这个字段列的数据，将数据从原来的存储弹性列批量拷贝到新的弹性列，然后才会更新此字段列的元数据，暨在 Fields 表中更新这个字段列的元数据，将数据类型更改为新的数据类型，并将 FieldNum 更新为新的 ValueX 列对应的X值。</li> </ul> <h3 id="多租户隔离和保护">多租户隔离和保护</h3> <ul> <li>监控每一个代码执行片段</li> <li>限制代码CPU执行时间，内存使用量</li> <li>限制代码DB查询和更新数量</li> <li>限制可执行的数学运算量</li> <li>限制外部接口调用量</li> <li>执行太耗时或太耗资源的操作，系统将抛出运行时异常</li> <li>单元测试覆盖率必须超过75%</li> </ul> <p>因为是多租户共享，严格的限制保证整体的可扩展性和性能 <br/> 长期来看，这些限制推动了开发写出了更好的代码</p> <h3 id="数据高可用">数据高可用</h3> <ul> <li>4 online copies</li> <li>2 standby copies</li> <li>本地热备切换速度更快</li> <li>异地热备使灾难切换少于15分钟</li> <li>每6个月切换一次（定期演练，验证）</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-data-availability-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-data-availability-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-data-availability-1400.webp"/> <img src="/assets/img/salesforce-data-availability.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 数据高可用 </div> <h3 id="可视化配置">可视化配置</h3> <h4 id="salesforce能配置什么">Salesforce能配置什么？</h4> <ul> <li>数据模型 <ul> <li>包括自定义的对象和它的相关字段，及其之间的关系。</li> <li>其实就是操作元数据</li> </ul> </li> <li>安全和共享模型 <ul> <li>包括用户，权限等</li> </ul> </li> <li>用户界面 <ul> <li>包括界面布局, 数据输入表单和报表等。</li> </ul> </li> <li>声明式逻辑 (工作流)</li> <li>编程式逻辑 (存储过程和触发器)</li> </ul> <h4 id="salesforce工作流">Salesforce工作流</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce_flow-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce_flow-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce_flow-1400.webp"/> <img src="/assets/img/salesforce_flow.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce工作流 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce_flow_builder-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce_flow_builder-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce_flow_builder-1400.webp"/> <img src="/assets/img/salesforce_flow_builder.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Salesforce工作流构建器 </div> <h4 id="配置数据模型和用户界面">配置数据模型和用户界面</h4> <ul> <li>对象管理器 <ul> <li>其实就是创建数据模型的地方，是后台配置对象，字段，页面布局等元数据的工具</li> </ul> </li> <li>配置用户界面 <ul> <li>列表视图 - 列表页 <ul> <li>在前端加载对象的记录列表时使用。例如客户列表</li> <li>利用元数据来展示业务数据。</li> </ul> </li> <li>页面布局 - (创建/更新/详情页） <ul> <li>在前端加载一条记录详情的时候使用，</li> <li>例如客户详情，新增/编辑客户信息页面。</li> </ul> </li> </ul> </li> </ul> <h5 id="可视化配置底层数据结构">可视化配置底层数据结构</h5> <p>橙色表示后台配置，蓝色表示前台界面</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-data-structure-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-data-structure-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-data-structure-1400.webp"/> <img src="/assets/img/salesforce-data-structure.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 可视化配置底层数据结构 </div> <h5 id="对象管理器">对象管理器</h5> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-object-manager-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-object-manager-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-object-manager-1400.webp"/> <img src="/assets/img/salesforce-object-manager.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 对象管理器 </div> <h5 id="对象object">对象（Object)</h5> <ul> <li>只有名称和APIName这两个重要的属性。</li> <li>创建一个新对象的时候，系统会自动帮你创建一些系统字段、一个页面布局，以及系统标准按钮数据。</li> <li>系统字段主要是指那些审计字段，例如：创建人、创建时间、最后更新人、最后更新时间、是否已删除等等。标准按钮主要是创建、编辑、删除等系统常规操作按钮。</li> </ul> <h5 id="字段field">字段（Field）</h5> <ul> <li>每个字段都需要有个数据类型</li> <li>一个字段只能属于1个对象</li> <li>字段的APIName在该对象上必须唯一</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-object-field-type-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-object-field-type-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-object-field-type-1400.webp"/> <img src="/assets/img/salesforce-object-field-type.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> </div> <div class="col-sm mt-3 mt-md-0"> </div> </div> <div class="caption"> 字段的数据类型 </div> <h5 id="列表视图">列表视图</h5> <p>可灵活控制列表需要展示的字段和顺序。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-list-view-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-list-view-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-list-view-1400.webp"/> <img src="/assets/img/salesforce-list-view.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 列表视图 </div> <h5 id="页面布局pagelayout">页面布局(PageLayout)</h5> <ul> <li>在前端加载一条记录详情的时候使用</li> <li>页面布局只要有2大块 <ul> <li>区域（PageLayoutSection）</li> <li>相关列表（RelatedList）</li> </ul> </li> <li>每个区域会有不同字段，可以是一列，两列，三列式</li> <li>相关列表指的是展示子记录的列表，可配置展示子记录的哪些列</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-page-layout-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-page-layout-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-page-layout-1400.webp"/> <img src="/assets/img/salesforce-page-layout.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 页面布局配置页面 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-page-related-list-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-page-related-list-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-page-related-list-1400.webp"/> <img src="/assets/img/salesforce-page-related-list.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 相关列表配置页面 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-detail-page-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-detail-page-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-detail-page-1400.webp"/> <img src="/assets/img/salesforce-detail-page.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 加载详情页面 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/salesforce-edit-page-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/salesforce-edit-page-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/salesforce-edit-page-1400.webp"/> <img src="/assets/img/salesforce-edit-page.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 加载新建和编辑页面 </div> <h3 id="总结salesforce的设计理念">总结Salesforce的设计理念</h3> <ul> <li>数据驱动 <ul> <li>元数据驱动</li> </ul> </li> <li>规模经济 <ul> <li>尽可能多用户共享同一套系统</li> </ul> </li> <li>定制方便</li> <li>功能丰富 <ul> <li>能让用户购买和整合第三方应用（AppExchange）</li> </ul> </li> <li>软件是一个进化的工程 <ul> <li>不断丰富的产品矩阵</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="architecture"/><summary type="html"><![CDATA[近段时间，我主要在从事CRM系统的架构工作，自然对业界相关的技术进行了一些调研，Salesforce是CRM领域的标杆和鼻祖，也是全球企业信息服务界的龙头。本文记录我调研整理的Salesforce的后端技术架构相关信息。]]></summary></entry><entry><title type="html">如何进行微服务拆分</title><link href="https://chenjun305.github.io/blog/2023/microservices/" rel="alternate" type="text/html" title="如何进行微服务拆分"/><published>2023-07-10T00:00:00+00:00</published><updated>2023-07-10T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/microservices</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/microservices/"><![CDATA[<p>设计一个微服务架构的三步式流程：</p> <ul> <li>分析系统操作</li> <li>进行服务拆分</li> <li>设计服务API和协作方式</li> </ul> <h3 id="根据业务能力进行服务拆分">根据业务能力进行服务拆分</h3> <p>业务能力是指一些能够为公司（或组织）产生价值的商业活动。</p> <p>组织的业务能力通常是指这个组织的业务是做什么，他们通常是稳定的。与之相反，组织采用何种方式来实现它的业务能力，是随着时间不断变化的。</p> <p>一个组织有哪些业务能力，是通过对组织的目标，结构和商业流程的分析得来的。</p> <p>一旦确定了业务能力，就可以为每个能力或相关能力组定义服务。</p> <p>围绕能力组织服务的一个关键好处是，因为它们是稳定的，所以最终的架构也将相对稳定。架构的各个组件可能会随着业务的具体实现方式的变化而发展，但架构能保持不变。</p> <h3 id="根据ddd子域进行服务拆分">根据DDD子域进行服务拆分</h3> <p>领域驱动为每一个子域定义单独的领域模型。子域是领域的一部分，领域是DDD中用来描述应用程序问题域的一个术语。识别子域跟识别业务能力一样，分析业务并识别业务的不同专业领域，分析产生的子域定义结果也会跟业务能力非常接近。</p> <p>DDD把领域模型的边界称为限界上下文。限界上下文包括实现这个代码的集合。当使用微服务架构时，每一个限界上下文对应一个或一组服务。换一种说法，我们可以通过DDD的方式定义子域，并把子域对应为每一个服务，这样就完成了微服务架构的设计工作。</p> <h3 id="拆分的指导原则">拆分的指导原则</h3> <ul> <li>单一职责原则（Single Responsibility Principle，SRP） <ul> <li>改变一个类应该只有一个理由</li> <li>设计小的，内聚的，仅仅含有单一职责的服务。这会缩小服务的大小并提升它的稳定性。</li> </ul> </li> <li>闭包原则（Common Closure Principle，CCP） <ul> <li>在包中包含的所有类应该是对同类的变化的一个集合，也就是说，如果对包做出修改，需要调整的类应该都在这个包之内。</li> <li>把根据同样原因进行变化的服务放在一个组件内。这样做可以控制服务的数量，当需求发送变化时，变更和部署也更加容易。</li> <li>理想情况下，一个变更只会影像一个团队和一个服务。CCP是解决分布式单体这种可怕的反模式的法宝。</li> </ul> </li> </ul> <h3 id="拆分单体为服务的难点">拆分单体为服务的难点</h3> <ul> <li>网络延迟</li> <li>同步进程间通信导致可用性降低</li> <li>分布式事务一致性</li> <li>上帝类阻碍了拆分</li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="architecture"/><summary type="html"><![CDATA[设计一个微服务架构的三步式流程： 分析系统操作 进行服务拆分 设计服务API和协作方式]]></summary></entry><entry><title type="html">如何提高代码可读性</title><link href="https://chenjun305.github.io/blog/2023/readable-code/" rel="alternate" type="text/html" title="如何提高代码可读性"/><published>2023-07-01T00:00:00+00:00</published><updated>2023-07-01T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/readable-code</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/readable-code/"><![CDATA[<p>先介绍一本好书</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/readable-code-book-english-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/readable-code-book-english-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/readable-code-book-english-1400.webp"/> <img src="/assets/img/readable-code-book-english.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/readable-code-book-chinese-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/readable-code-book-chinese-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/readable-code-book-chinese-1400.webp"/> <img src="/assets/img/readable-code-book-chinese.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 编写可读代码的艺术 </div> <p>以下代码可读性好吗？</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if ( !isNotEmpty(str) ) {

} else {
    do();
}
</code></pre></div></div> <p>这样写是不是更好？</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if ( isEmpty(str) ) {

} else {
    do();
}

</code></pre></div></div> <h3 id="高可读性代码定义">高可读性代码定义</h3> <ul> <li>定义：使别人用最短的时间理解你的代码</li> <li>这里的别人也包括1个月后的自己</li> <li>不给别人挖坑=不给自己挖坑</li> <li>不要让别人看到我们的代码一脸懵逼</li> </ul> <h3 id="高可读性代码的4个要素">高可读性代码的4个要素</h3> <ul> <li>命名</li> <li>注释</li> <li>简化循环和控制逻辑</li> <li>重构你的代码</li> </ul> <h4 id="命名">命名</h4> <ul> <li>包括类名，方法名，变量名，常量名等等</li> <li>达到见名知意</li> <li>使用明确的，正确的，常用的简单英语单词 <ul> <li>Bespeak是什么意思？（尽量不要使用不常用的单词）</li> <li>90%的情况下高中为止的单词就足够了</li> </ul> </li> </ul> <h5 id="使用明确正确简单的单词">使用明确，正确，简单的单词</h5> <ul> <li>从外部加载页面 <ul> <li><code class="language-plaintext highlighter-rouge">Page getPage() {</code> : 不够准确</li> <li><code class="language-plaintext highlighter-rouge">Page loadPage() {</code> : 更准确一些</li> </ul> </li> <li>通过名字检索 <ul> <li><code class="language-plaintext highlighter-rouge">List&lt;Person&gt; getByName(String name) {</code> : 不够准确，get方法一般只会返回1个对象</li> <li><code class="language-plaintext highlighter-rouge">List&lt;Person&gt; findByName(String name) {</code> : 更准确一些</li> </ul> </li> </ul> <h5 id="使用更具体的名称">使用更具体的名称</h5> <ul> <li>把Date转化为yyyyMMdd形式的字符串 <ul> <li><code class="language-plaintext highlighter-rouge">String toDateString(Date date)</code> ： 不够具体</li> <li><code class="language-plaintext highlighter-rouge">String toYYYYMMDD(Date date)</code> ： 更具体，基本上见名知意</li> </ul> </li> <li>字符串列表中返回符合条件的下标列表 <ul> <li>写法1: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>List&lt;Integer&gt; result = new ArrayList&lt;&gt;();
 //……
 return result;
</code></pre></div> </div> </li> <li>写法2: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>️List&lt;Integer&gt; matchedIndexes = new ArrayList&lt;&gt;();
 //……
 return matchedIndexes;
</code></pre></div> </div> </li> <li>上面两种写法中，变量名matchedIndexes取得更具体，理解成本更低。</li> </ul> </li> </ul> <h5 id="什么时候可以缩写省略">什么时候可以缩写/省略</h5> <ul> <li>不可以省略的情况 <ul> <li><code class="language-plaintext highlighter-rouge">class WDate {}</code> : 这里把War缩写成W就不知道什么意思了</li> <li><code class="language-plaintext highlighter-rouge">class WarDate {}</code></li> </ul> </li> <li>可以省略的情况 <ul> <li><code class="language-plaintext highlighter-rouge">Document doc = new Document();</code> : document缩写成doc基本不影响理解，而且基本是业界约定俗成的缩写</li> <li><code class="language-plaintext highlighter-rouge">Document document = new Document();</code></li> <li><code class="language-plaintext highlighter-rouge">Date convertToDate(String dateExpression, String datePattern);</code></li> <li><code class="language-plaintext highlighter-rouge">Date toDate(String dateExpression, String datePattern);</code> ： 去除convert这个单词也不影响意思表达</li> </ul> </li> <li>这里需要注意的是，命名并不是越长越好，名字太长，也会增加读者理解成本</li> </ul> <h5 id="灵活使用前缀和后缀">灵活使用前缀和后缀</h5> <ul> <li>检查文件大小 <ul> <li><code class="language-plaintext highlighter-rouge">public boolean isFileSizeOver(File file, int size)</code></li> <li><code class="language-plaintext highlighter-rouge">public boolean isFileSizeOver(File file, int size_kb)</code> : 这里的参数名size_kb很好地传达了单位是kb, 可以使读者更好地理解方法的意图。</li> </ul> </li> <li>boolean型变量或方法，使用is, has, can, should等前缀 <ul> <li><code class="language-plaintext highlighter-rouge">if ( user.auth() ) {</code></li> <li>` if ( user.hasAuthority() )` : 有has前缀，很容易理解该方法返回值类型为boolean</li> </ul> </li> </ul> <h5 id="命名时的要点">命名时的要点</h5> <ul> <li>见名知意</li> <li>从多个候选单词中找出一个最正确，最明确的</li> <li>选一个最不会引起误解的单词</li> <li>参考其他同学的意见</li> <li>要有工匠精神，精益求精</li> </ul> <h4 id="注释">注释</h4> <p>首先，我并不认为注释越多越好，长篇大论，同样也会增加阅读成本，浪费读者的时间。<br/> 不要写没有价值的注释，看代码就明白什么意思的情况不要写注释.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//通过名字检索
  List&lt;Person&gt; findByName(String name) {
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//遍历array数组
  For (int i=0; i&lt;array.count; i++) {
</code></pre></div></div> <p>上面两个例子中的注释，是没有必要的，因为看代码其实已经理解意思了。这样的注释只是增加了代码行数。（除非你所在的公司会考核工程师的代码行数）</p> <h5 id="什么时候应该写注释">什么时候应该写注释</h5> <ul> <li>常量（magic number)的背景</li> <li>有可能让人产生疑问的地方</li> <li>BUG／踩过的坑的注释</li> <li>复杂的或独特的功能或算法</li> <li>注释应该与代码行为一致</li> </ul> <h4 id="简化循环和控制逻辑">简化循环和控制逻辑</h4> <p>这里主要是要减少理解的曲折度，能直着说就别绕着说，减少理解代码所需的脑容量。</p> <ul> <li>变化的放在左边 <ul> <li><code class="language-plaintext highlighter-rouge">if(10&lt;length)</code></li> <li><code class="language-plaintext highlighter-rouge">if (length &gt; 10)</code> : 把变量放到左边更符合程序员的思维习惯</li> </ul> </li> <li>if-else尽量把肯定排在前面</li> <li>循环层次不可太深，最好不要超过3层</li> <li>循环时break, continue尽早返回</li> <li>if-else条件语句尽量把肯定放在前面 <ul> <li>写法1 <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if ( ! user.hasAuthority(“admin”) ) {
// ..
} else {
// ..
}
</code></pre></div> </div> </li> <li>写法2 <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if ( user.hasAuthority(“admin”) ) {
// ..
} else {
// ..
}
</code></pre></div> </div> <p>写法2，if条件是肯定语句，更好理解一些。</p> </li> </ul> </li> </ul> <h4 id="重构代码">重构代码</h4> <ul> <li>列出所有任务并把它们分开</li> <li>一个方法只完成1个任务</li> <li>当1个类上千行或者1个方法上百行时，通常意味着应该把他们分成不同的类或方法</li> <li>持续重构，持续改进</li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="architecture"/><summary type="html"><![CDATA[先介绍一本好书]]></summary></entry><entry><title type="html">k8s</title><link href="https://chenjun305.github.io/blog/2023/k8s/" rel="alternate" type="text/html" title="k8s"/><published>2023-04-07T00:00:00+00:00</published><updated>2023-04-07T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/k8s</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/k8s/"><![CDATA[<h2 id="k8s-architecture">K8S architecture</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/k8s-architecture-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/k8s-architecture-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/k8s-architecture-1400.webp"/> <img src="/assets/img/k8s-architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> K8S architecture </div> <h3 id="control-plane-控制平面">Control Plane 控制平面</h3> <h4 id="kube-apiserver">kube-apiserver</h4> <p>负责API服务</p> <h4 id="etcd">etcd</h4> <p>整个集群的持久化数据，都是由kube-apiserver经过处理后保存在etcd中。</p> <h4 id="kube-scheduler">kube-scheduler</h4> <p>负责调度功能，负责为Pod分配最合适的节点。</p> <h4 id="kube-controller-manager">kube-controller-manager</h4> <p>负责容器编排，包含很多不同功能的控制器。</p> <h3 id="node-components-节点组件">Node Components 节点组件</h3> <h4 id="kublet">kublet</h4> <ul> <li>运行在每个节点上;由于需要直接操作宿主机，一般直接安装在每台宿主机上，不像别的组件一般以容器方式部署；</li> <li>通过CRI（Container Runtime Interface）同容器运行时交互；</li> <li>通过CNI（Container Network Interface）调用网络插件为容器配置网络;</li> <li>通过CSI（Container Storage Interface）调用存储插件为容器配置持久化存储;</li> <li>通过gRPC协议同一个叫做Device Plugin的插件进行交互，这个插件，是kubernetes用来管理GPU等宿主机物理设备的主要组件。</li> </ul> <h4 id="kube-proxy">kube-proxy</h4> <p>通过操作iptables实现集群内网络路由相关功能（比如Service）。</p> <h4 id="container-runtime-容器运行时">Container runtime 容器运行时</h4> <p>管理容器的执行和生命周期。 只要你的容器运行时能够运行标准的容器镜像，它就可以通过实现CRI接入Kubernetes。 而具体的容器运行时，比如Docker，一般通过OCI这个容器运行时规范同底层的Linux进行交互，即把CRI请求转化成对操作系统的调用（操作Linux namespace和Cgroups等）</p> <h2 id="部署工具kubeadm">部署工具kubeadm</h2> <p>kubeadm的工作原理是直接在宿主机上运行kubelet, 然后使用容器部署其他kubernetes组件。</p> <p>实际上，kubeadm几乎完全是一位高中生的作品。他叫Lucas Kaldstrom, 芬兰人。kubeadm是他17岁时用业余时间完成的一个社区项目。</p> <p>并且kubeadm是可以用于生产环境的，在kubernetes v1.14发布后，kubeadm项目已经正式宣布GA（General availability, 生产可用）了。</p> <h3 id="部署步骤">部署步骤</h3> <ul> <li>安装kubeadm和docker</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ apt-get install -y docker.io kubeadm
</code></pre></div></div> <p>上述安装kubeadm的过程中，会自动安装kubeadm, kubelet, kubectl和kubernetes-cni这几个二进制文件。</p> <ul> <li>部署Master节点</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubeadm init --config kubeadm.yaml
</code></pre></div></div> <p>kubeadm.yaml是自定义的部署配置。 部署完成后，会生成一行kubeadm join命令，把它复制保存好，后面部署worker节点时需要用到。 kubeadm还会提示配置kube config等，复制命令执行即可。</p> <ul> <li>部署网络插件</li> </ul> <p>部署选型的网络插件，下面是weave的情况。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
</code></pre></div></div> <ul> <li>部署worker节点</li> </ul> <p>执行kubeadm init步骤时提示的kubeadm join命令。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubeadm join xxxx:6443 --token xxxx --discovery-token-ca-cert-hash xxxx
</code></pre></div></div> <h2 id="kubernetes编排原理">kubernetes编排原理</h2> <h3 id="pod">Pod</h3> <ul> <li>Pod是kubernetes项目的原子调度单位；</li> <li>Pod的实现需要使用一个中间容器，这个容器叫做Infra容器，Infra容器永远是第一个被创建的容器，用户定义的其他容器通过Join Network Namespace的方式与Infra容器关联在一起。Infra容器占用极少的资源，使用的是一个非常特殊的镜像，叫做k8s.gcr.io/pause。这个镜像是一个用汇编语言编写的，永远处于“暂停”状态的容器，解压后的大小也只有100～200KB</li> </ul> <h3 id="deployment">Deployment</h3> <ul> <li>Deployment控制ReplicaSet（版本），ReplicaSet控制Pod（副本数），这个两层控制关系一定要牢记。</li> <li>Deployment通过创建一个新的RelicaSet，不断新增新ReplicaSet的Pod数量，同时减少旧ReplicaSet的Pod数量的方式实现滚动更新应用版本。</li> </ul> <h3 id="statefulset">StatefulSet</h3> <ul> <li>StatefulSet的控制器直接管理的是Pod，每个Pod的hostname，名字等都不同，都携带了编号。</li> <li>k8s通过Headless Service为这些有编号的Pod，在DNS服务器中生成带有相同编号的DNS记录。</li> <li>StatefulSet还为每一个Pod分配并创建一个相同编号的PVC。即使Pod被删除，它所对应的PVC和PV依然会保存下来，当这个Pod被重建后，由于编号相同，它还可以获取以前保存在Volume里的数据。</li> <li>同样，只要修改了StatefulSet的Pod模版，即可自动触发滚动更新。StatefulSet Controller会按照与Pod编号相反的顺序，从最后一个Pod开始，逐一更新这个StatefulSet管理的每个Pod。</li> </ul> <h3 id="daemonset">DaemonSet</h3> <ul> <li>DaemonSet的Pod在Kubernetes集群的每一个节点运行</li> <li>每个节点上只有一个这样的Pod实例。</li> <li>当有新节点加入kubernetes集群后，该Pod会自动地在新节点上被创建出来。节点被删除后，上面的Pod也会相应地被回收。</li> </ul> <p>使用场景：</p> <ul> <li>各种网络插件的Agent组件都必须在每一个节点运行；</li> <li>各种存储插件的Agent组件都必须在每一个节点运行；</li> <li>各种监控组件和日志组件都必须在每一个节点运行。</li> </ul> <h3 id="离线业务job与cronjob">离线业务：Job与CronJob</h3> <p>对于CronJob，笔者在实践中踩过坑，对于需要频繁执行的定时任务来说，比如每5秒执行一次的定时任务，使用CronJob将不是一个好主意，这会导致每5秒就要创建1个新Pod，会给整个Kubernetes集群带来很大的负载压力。</p>]]></content><author><name></name></author><category term="programming"/><category term="k8s"/><summary type="html"><![CDATA[K8S architecture]]></summary></entry><entry><title type="html">docker使用</title><link href="https://chenjun305.github.io/blog/2023/docker-command/" rel="alternate" type="text/html" title="docker使用"/><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/docker-command</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/docker-command/"><![CDATA[<h2 id="docker-command"><a href="https://docs.docker.com/engine/reference/commandline/cli/">docker command</a></h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/docker-command.webp-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/docker-command.webp-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/docker-command.webp-1400.webp"/> <img src="/assets/img/docker-command.webp" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> docker command </div> <h3 id="构建镜像">构建镜像</h3> <ul> <li><a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a></li> </ul> <p>Dockerfile的设计思想是使用一些标准原语描述所要构建的Docker镜像，并且这些原语都是按顺序处理的。<br/> 以下是一个构建python应用的例子：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#使用官方提供的Python开发镜像作为基础镜像
FROM python:2.7-slim

#将工作目录切换为 /app
WORKDIR /app

#将当前目录下的所有内容复制到 /app下
ADD . /app

#使用pip命令安装这个应用所需要的依赖
#RUN原语就是在容器里执行shell命令
RUN pip install --trusted-host pypi.python.org -r requirements.txt

#允许外界访问容器的80端口
EXPOSE 80

#设置环境变量
ENV NAME World

#设置容器进程为: python app.py
CMD ["python","app.py"]   
</code></pre></div></div> <p>另外在使用Dockerfile时，你可能还会看到叫ENTRYPOINT的原语, 实际上它和CMD都是Docker容器进程启动所必须的参数.<br/> 完整执行格式是: <code class="language-plaintext highlighter-rouge">ENTRYPOINT CMD</code><br/> 在默认情况下Docker会提供一个隐含的ENTRYPOINT，即: <code class="language-plaintext highlighter-rouge">/bin/sh -c</code><br/> 所以在这个例子里，实际运行在容器里的完整进程是: <code class="language-plaintext highlighter-rouge">/bin/sh -c "python app.py"</code></p> <ul> <li><code class="language-plaintext highlighter-rouge">docker build</code></li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker bulid -t helloworld . 
</code></pre></div></div> <p>docker build会自动加载当前目录下的Dockerfile文件，然后按照顺序执行文件中的原语。 -t的作用是给这个镜像加一个Tag，即起名字 Dockerfile中的每个原语执行后，都会生成一个对应的镜像层，即使原语本身并没有明显修改文件的操作（如ENV原语），它对应的层也会存在，只不过在外界看来是空的</p> <ul> <li><code class="language-plaintext highlighter-rouge">docker commit</code></li> </ul> <p>除了<code class="language-plaintext highlighter-rouge">docker build</code>命令，还可以使用<code class="language-plaintext highlighter-rouge">docker commit</code>指令，把一个正在运行的容器，直接提交一个镜像。<code class="language-plaintext highlighter-rouge">docker commit</code>实际上是容器运行起来后，把最上层的可读写层，加上原先容器镜像的只读层（在宿主机上共享，不会占用额外的空间），打包组成了一个新的镜像。</p> <ul> <li>查看镜像(<code class="language-plaintext highlighter-rouge">docker image</code>)</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker image ls
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE
helloworld                           latest              482458a88f79        2 hours ago         131MB
</code></pre></div></div> <h3 id="启动容器">启动容器</h3> <ul> <li><code class="language-plaintext highlighter-rouge">docker run</code></li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -p 4000:80 helloworld
</code></pre></div></div> <p>因为在Dockerfile中已经制定了CMD，否则就的把进程启动命令加载后面：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -p 4000:80 helloworld python app.py
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">-p 4000:80</code>是把容器内的80端口映射在宿主机的4000端口上。 这样做得目的是只要访问宿主机的4000端口就可以看到容器里应用返回的结果， 否则就要先用<code class="language-plaintext highlighter-rouge">docker inspect</code>命令查看容器的IP地址，然后访问“http://<容器IP地址>：80”才可以看到容器内应用的返回.</容器IP地址></p> <ul> <li>查看容器（<code class="language-plaintext highlighter-rouge">docker ps</code>)</li> </ul> <h3 id="docker-hub"><a href="https://hub.docker.com/">Docker Hub</a></h3> <p>如果需要上传到Docker Hub, 则需要先注册账号，然后通过<code class="language-plaintext highlighter-rouge">docker login</code>命令登录，然后用<code class="language-plaintext highlighter-rouge">docker tag</code>给容器起一个完整的名字.最后通过<code class="language-plaintext highlighter-rouge">docker push</code>命令上传到docker hub.</p> <p>我们企业内部内部能否也搭建一个跟Docker Hub类似的镜像上传系统呢？<br/> 当然可以，这个统一存放镜像的系统就叫做<a href="https://docs.docker.com/registry/spec/api/">Docker Registry</a>, 也可以查看VMware的<a href="https://goharbor.io/">Harbor</a>项目。</p> <h2 id="docker-compose"><a href="https://docs.docker.com/compose/reference/">docker compose</a></h2> <h3 id="composeyaml"><a href="https://docs.docker.com/compose/compose-file/">compose.yaml</a></h3> <p>定义多容器应用。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:
  web:
    build: .
    ports:
      - "8000:5000"
  redis:
    image: "redis:alpine"
</code></pre></div></div> <p>the web service uses an image that’s built from the Dockerfile in the current directory.</p> <ul> <li><code class="language-plaintext highlighter-rouge">docker compose up</code> 或 <code class="language-plaintext highlighter-rouge">docker compose up -d</code> Create and start containers</li> <li>查看 <code class="language-plaintext highlighter-rouge">docker compose ps</code> List containers</li> <li>停止 <code class="language-plaintext highlighter-rouge">docker compose stop</code> Stop services</li> <li><code class="language-plaintext highlighter-rouge">docker compose down --volumes</code> Stop and remove containers, networks, also remove the data volume</li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="docker"/><summary type="html"><![CDATA[docker command]]></summary></entry><entry><title type="html">docker原理</title><link href="https://chenjun305.github.io/blog/2023/docker/" rel="alternate" type="text/html" title="docker原理"/><published>2023-04-03T00:00:00+00:00</published><updated>2023-04-03T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/docker</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/docker/"><![CDATA[<p>容器的本质是一种特殊的进程，通过Linux Namespace实现“隔离”，使进程只能看到该Namespace内的“世界”，通过Linux Cgroups实现限制，使进程只能使用配额的CPU，内存等系统资源。而它运行所需要的各种文件，整个操作系统文件，是由多个联合挂载在一起的rootfs层提供。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/docker-vs-vm-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/docker-vs-vm-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/docker-vs-vm-1400.webp"/> <img src="/assets/img/docker-vs-vm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> docker vs vm </div> <h2 id="通过linux-namespace机制实现容器的隔离">通过Linux Namespace机制实现容器的隔离</h2> <p>Namespace机制是Linux内核提供的一种隔离资源的机制。Docker使用Namespace实现容器之间的隔离:</p> <ul> <li>PID namespace:隔离进程ID,使得容器内外的同一个PID实际上对应不同的进程。</li> <li>IPC namespace:隔离系统间消息队列、信号量和共享内存对象,使得这些资源在容器之间隔离。</li> <li>Network namespace:隔离网络设备、IP地址和端口,每个容器都有自己的网络接口、IP地址和端口。</li> <li>UTS namespace:隔离主机名和域名,每个容器可以有自己的主机名。</li> <li>Mount namespace:隔离挂载点,每个容器都有自己的根文件系统(rootfs)。</li> <li>User namespace:隔离用户和组ID,使得容器内外用户和组ID相同的用户实际上是不同的用户。</li> </ul> <p>Docker项目帮助用户启动的还是原来的的应用进程，只不过在创建这些进程时，Docker为它们加上了各种各样的Namespace参数。以PID namespace为例,在Linux系统中创建进程的系统调用是<code class="language-plaintext highlighter-rouge">clone()</code>,它允许在创建新进程时指定Namespace类型(<code class="language-plaintext highlighter-rouge">CLONE_NEWPID</code>), 这时，新创建的进程将会“看到”一个全新的进程空间。在这个空间里，它的PID是1.在宿主机的真实进程空间里，这个进程的PID还是真实的数值，比如100.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int pid = clone(main_func, stack_size, CLONE_NEWPID | SIGCHLD, NULL);
</code></pre></div></div> <p>可见，容器其实是一种特殊的进程而已。</p> <p>与传统虚拟机相比,容器的优势在于:</p> <ul> <li>容器化的应用依然是宿主机上的普通进程，不存在因为虚拟化而产生的性能损耗。</li> <li>不需要单独的客户操作系统，容器内的应用直接运行于宿主机的内核,从而更轻量级。</li> </ul> <p>不过，有利就有弊，基于Linux Namespace的隔离机制相比于虚拟化技术也有很多不足之处。</p> <ul> <li>隔离的不彻底，容器内外还是共享很多系统资源,比如主机的内核、时间源等。这给安全性带来一定风险。</li> <li>如果要在Windows宿主机上运行Linux容器，或在低版本的Linux主机上运行高版本的Linux容器，都是行不通的。</li> <li>Linux内核中，有很多资源是不能被Namespace化的，最典型的例子就是：时间</li> </ul> <p>所以，在生产环境中，没人敢把在物理机上运行的Linux容器直接暴露在公网上。</p> <h2 id="通过linux-cgroups实现容器资源限制">通过Linux Cgroups实现容器资源限制</h2> <p>Linux Cgroups (Linux Control groups)最主要的作用就是限制一个进程组能够使用的资源上限，包括CPU，内存，磁盘，网络带宽，等等。<br/> 此外，Cgroups还能对进程进行优先级设置，审计，及将将进程挂起和恢复等操作。<br/> 在Linux中，Cgroups向用户暴露出来的操作接口是文件系统，在/sys/fs/cgroup路径下。<br/> 可以用<code class="language-plaintext highlighter-rouge">mount</code>指令将其显示：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ mount -t cgroup
cpuset on /sys/fs/cgroup/cpuset
cpu on /sys/fs/cgroup/cpu
cpuacct  on /sys/fs/cgroup/cpuacct
blkio on /sys/fs/cgroup/blkio
memory on /sys/fs/cgroup/memory
</code></pre></div></div> <p>Cgroups的每一项子系统都有其独有的资源限制能力，比如</p> <ul> <li>cpu， 为进程设置cpu使用配额；</li> <li>cpuset， 主要用于设置CPU的亲和性，可以限制cgroup中的进程只能在指定的CPU上运行，或者不能在指定的CPU上运行，同时cpuset还能设置内存的亲和性;</li> <li>cpuacct, 包含当前cgroup所使用的CPU的统计信息;</li> <li>blkio， 为块设备设定I/O限制，一般用于磁盘等设备；</li> <li>memory， 为进程设定内存使用限制；</li> </ul> <p>使用方法为在需要限制资源的子系统路径下创建“控制组”文件夹，在该文件夹下再将限制信息进行修改。最后将需要限制的进程ID写入文件夹下的tasks文件。<br/> 例如，以下docker run命令：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash
</code></pre></div></div> <p>启动这个容器后，查看相关限制文件：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat /sys/fs/cgroup/cpu/docker/&lt;id&gt;/cpu.cfs_period_us
100000
$ cat /sys/fs/cgroup/cpu/docker/&lt;id&gt;/cpu.quota_us
20000
</code></pre></div></div> <p>这就意味着这个docker容器只能使用20%的cpu。</p> <p>但是，Cgroups对资源的限制能力也有很多不完善之处，比如/proc文件系统的问题。<br/> /proc下是表示当前内核运行状态的一系列特殊文件，比如CPU使用情况，内存占用率等。<br/> 这些文件也是top指令查看系统信息的主要数据来源。<br/> 但如果在容器内执行top命令，显示的却是宿主机的CPU和内存数据。<br/> 原因是/proc文件系统不了解Cgroups限制的存在。<br/> 这个问题是企业容器化应用中碰到的一个常见问题。</p> <h2 id="深入理解容器镜像">深入理解容器镜像</h2> <h3 id="rootfs文件系统">rootfs文件系统</h3> <p>Mount Namespace修改的是容器进程对文件系统“挂载点”的认知，只有这个“挂载”操作发生之后，进程的视图才会改变，而在这之前，新创建的容器会直接继承宿主机的各个挂载点。<br/> 但我们希望容器”看到“的文件系统就是一个独立的隔离环境，所以在容器启动之前，可以重新挂载它的整个根目录”/“，并为这个根目录挂载一个完整操作系统的文件系统.<br/> 这个挂载在容器根目录上用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有1个更专业的名字，rootfs（根文件系统）。</p> <p>Docker项目最核心的原理就是为待创建的用户进程：</p> <ul> <li>启用Linux Namespace配置；</li> <li>设置指定的Cgroups参数；</li> <li>切换进程的根目录（change root)。</li> </ul> <p>这样，一个完整的容器就诞生了。</p> <p>Docker在最后一步的切换上，优先使用pivot_root系统调用，如果系统不支持，则会使用<code class="language-plaintext highlighter-rouge">chroot</code>命令。</p> <p>但是，需要明确的是，rootfs只是一个操作系统所包含的目录，文件，配置，并不包含操作系统内核。<br/> 同一机器上的所有容器都共享宿主机操作系统内核，如果容器内应用程序需要配置内核参数，加载额外的内核模块，以及跟内核进行直接交互，就需要注意了，这些操作的对象都是宿主机操作系统的内核。</p> <h3 id="docker-image-layer">docker image layer</h3> <p>docker在镜像的设计中引入了层（layer）的概念，用户制作镜像的每一步操作都会生成一个层，也就是一个增量的rootfs。<br/> 它使用UnionFS（union file system，联合文件系统）的能力，将不同位置的目录联合挂载（union mount）到同一目录下。<br/> 例如，在Ubuntu下是使用AuFS这个UnionFS的实现。镜像的层是放置在<code class="language-plaintext highlighter-rouge">/var/lib/docker/aufs/diff/&lt;layer_id&gt;</code>目录下，然后被联合挂载在<code class="language-plaintext highlighter-rouge">/var/lib/docker/aufs/mnt/&lt;ID&gt;</code>中。<br/> 容器的roofs的层可分为3部分：</p> <ul> <li>只读层（ro+wh, 即readonly+whiteout)</li> <li>Init层（ro+wh），用来存放<code class="language-plaintext highlighter-rouge">/etc/hosts</code>, <code class="language-plaintext highlighter-rouge">/etc/resolv.conf</code>等信息，docker commit不包含这一层的内容。</li> <li>可读写层（rw），rootfs最上面的一层，如果要删除只读层里的一个文件，AuFS会在可读写层创建一个whiteout文件，把只读层里的文件遮挡起来。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/docker-image-layers-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/docker-image-layers-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/docker-image-layers-1400.webp"/> <img src="/assets/img/docker-image-layers.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> docker image layers </div> <h2 id="docker-exec的工作原理"><code class="language-plaintext highlighter-rouge">docker exec</code>的工作原理</h2> <p>我们知道，在宿主机上可以通过<code class="language-plaintext highlighter-rouge">docker exec -it ...</code>命令进入容器，它是如何实现的呢？<br/> 一个进程的每种Namespace信息在宿主机上是存在的，并且以文件的形式存在，对应的目录是<code class="language-plaintext highlighter-rouge">/proc/[进程号]/ns/</code>下有一个对应的虚拟文件，并且链接到一个真实的Namespace文件上。 <code class="language-plaintext highlighter-rouge">docker exec</code>的原理就是加入容器进程的namespace，这样就可以看到和容器进程一样的视图了。</p> <p>另外，<code class="language-plaintext highlighter-rouge">docker run</code>命令还提供了一个参数<code class="language-plaintext highlighter-rouge">--net</code>, 可以启动一个容器并“加入”另一个容器的Network Namespace中，比如：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --net container:&lt;id&gt; busybox ifconfig
</code></pre></div></div> <p>而如果指定<code class="language-plaintext highlighter-rouge">--net=host</code>,则直接共享宿主机的网络栈。</p> <h2 id="docker-volume的工作原理">docker volume的工作原理</h2> <p>Volume(数据卷)机制可以将宿主机上的目录或文件挂载到容器中进行读取和修改。 支持两种声明方式：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run -v /test ...

$ docker run -v /home:/test
</code></pre></div></div> <p>以上两种方式都是把一个宿主机的目录挂载进容器的/test目录。<br/> 第一种没有显式地声明宿主机目录，Docker默认在宿主机创建一个临时目录<code class="language-plaintext highlighter-rouge">/var/lib/docker/volumes/[VOLUME_ID]/_data</code>,然后挂载到/test目录上。<br/> 第二种是直接将宿主机的/home目录挂载到了容器的/test目录上。</p> <p>在rootfs准备好之后，在执行chroot之前，把volume指定的宿主机目录（比如/home）挂载到指定的容器目录在宿主机上对应的目录（<code class="language-plaintext highlighter-rouge">/var/lib/docker/aufs/mnt/[可读写层ID]/test</code>)上，这个Volume挂载工作就完成了。<br/> 并且由于Mount Namespace已经开启了，宿主机上看不到这个挂载点。</p> <p>Docker创建的一个容器初始化进程（dockerinit)会负责完成根目录的准备，挂载设备和目录，配置hostname等一系列需要在容器内进行的初始化操作。<br/> 最后，它通过execv()系统调用让应用进程取代自己成为容器里PID=1的进程。</p> <h2 id="最后">最后</h2> <p>本文总结了Linux容器的核心实现原理，需要注意的是，Docker on Mac 以及 Windows Docker（Hyper-V实现）等实际上是基于虚拟化技术实现的，与Linux容器完全不同。</p>]]></content><author><name></name></author><category term="programming"/><category term="docker"/><summary type="html"><![CDATA[容器的本质是一种特殊的进程，通过Linux Namespace实现“隔离”，使进程只能看到该Namespace内的“世界”，通过Linux Cgroups实现限制，使进程只能使用配额的CPU，内存等系统资源。而它运行所需要的各种文件，整个操作系统文件，是由多个联合挂载在一起的rootfs层提供。]]></summary></entry><entry><title type="html">深入理解Linux网络</title><link href="https://chenjun305.github.io/blog/2023/linux-network/" rel="alternate" type="text/html" title="深入理解Linux网络"/><published>2023-03-11T00:00:00+00:00</published><updated>2023-03-11T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/linux-network</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/linux-network/"><![CDATA[<h2 id="内核是如何接收网络包的">内核是如何接收网络包的</h2> <p>当用户执行完recvfrom调用后，用户进程就通过系统调用进行到内核态工作了。如果接收队列没有数据，进程就进入睡眠状态被操作系统挂起。</p> <ol> <li>数据帧从外部网络到达网卡</li> <li>网卡把帧DMA到内存</li> <li>硬中断通知CPU</li> <li>CPU响应硬中断，简单处理后发出软中断</li> <li>ksoftirqd线程处理软中断，调用网卡驱动注册的poll函数开始收包</li> <li>帧被从RingBuffer上摘下来保存为一个SKB</li> <li>协议层开始处理网络帧，处理完后的数据data被放到Socket的接收队列中</li> <li>内核唤醒用户进程</li> </ol> <ul> <li>RingBuffer到底是什么, RingBuffer为什么会丢包？</li> </ul> <p>网卡在收到数据的时候以DMA的方式将包写到RingBuffer中。软中断收包的时候来这里把SKB取走，并申请新的SKB重新挂上去。</p> <p>RingBuffer的大小是可以设置的，长度可以通过ethtool工具查看。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ethtool -g ens3
Ring parameters for ens3:
Pre-set maximums:
RX:		256
RX Mini:	n/a
RX Jumbo:	n/a
TX:		256
Current hardware settings:
RX:		256
RX Mini:	n/a
RX Jumbo:	n/a
TX:		256
</code></pre></div></div> <p>如果内核处理不及时导致RingBuffer满了，那后面新来的数据包就会被丢弃，通过ethtool或ifconfig工具可以查看是否有RingBuffer溢出发生。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ethtool -S  ens3
NIC statistics:
     rx_queue_0_packets: 857
     rx_queue_0_bytes: 306826
     rx_queue_0_drops: 0
     rx_queue_0_xdp_packets: 0
     rx_queue_0_xdp_tx: 0
     rx_queue_0_xdp_redirects: 0
     rx_queue_0_xdp_drops: 0
     rx_queue_0_kicks: 1
     tx_queue_0_packets: 668
     tx_queue_0_bytes: 105070
     tx_queue_0_xdp_tx: 0
     tx_queue_0_xdp_tx_drops: 0
     tx_queue_0_kicks: 634
</code></pre></div></div> <p>修改RingBuffer大小, 不过改大之后会增加处理网络包的延时。另外一种解决思路更好，那就是让内核处理网络包的速度更快一些。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ethtool -G ens3 rx 4096 tx 4096
</code></pre></div></div> <ul> <li>ksoftirqd内核线程是干什么的？</li> </ul> <p>机器上有几个核，内核就会创建几个ksoftirqd线程出来。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ps -ef | grep ksoftirqd
root          13       2  0 20:50 ?        00:00:00 [ksoftirqd/0]
</code></pre></div></div> <p>ksoftirqd内核线程包含了所有的软中断处理逻辑。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat /proc/softirqs
                    CPU0
          HI:          0
       TIMER:      21167
      NET_TX:          1
      NET_RX:       1908
       BLOCK:      11021
    IRQ_POLL:          0
     TASKLET:         74
       SCHED:          0
     HRTIMER:          0
         RCU:      22435
</code></pre></div></div> <ul> <li>为什么网卡开启多队列能提升网络性能</li> </ul> <p>现在主流网卡基本上都是支持多队列的，通过ethtool可以查看：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ethtool -l  ens3
Channel parameters for ens3:
Pre-set maximums:
RX:		n/a
TX:		n/a
Other:		n/a
Combined:	4
Current hardware settings:
RX:		n/a
TX:		n/a
Other:		n/a
Combined:	1
</code></pre></div></div> <p>通过sysfs文件系统可以看到真正生效的队列数。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls /sys/class/net/ens3/queues/
rx-0  tx-0
</code></pre></div></div> <p>如果想加大队列数，ethtool也可以搞定</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ethtool -L ens3 combined 2
</code></pre></div></div> <p>通过/proc/interrupts可以看到该队列对应的硬件中断号。再通过该中断号对应的smp_affinity可以查看到亲和的CPU核是哪一个？</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat /proc/interrupts
...

$ cat /proc/irq/&lt;中断号&gt;/smp_affinity
8
</code></pre></div></div> <p>这个亲和性是通过二进制中的比特位来标记的。例如8是二进制的1000， 第4位是1，代表是第4个CPU核心-CPU3</p> <p>每个队列都有独立的，不同的中断号。所以不同的队列可以向不同的CPU发起硬中断通知。且相应的软中断也是由这个核处理的。</p> <p>所以工作中，如果网络包的接收频率高而导致个别核si偏高，那么通过加大网卡队列数，并设置每个队列中断号上的smp_affinity, 将各个队列的硬中断打散到不同的CPU就行了。</p> <ul> <li>tcpdump是如何工作的</li> </ul> <p>tcpdump工作在设备层，是通过虚拟协议栈的形式工作的。将抓包函数以协议的形式挂到ptype_all上。</p> <p>当收包的时候，驱动在将包送到协议栈（ip_rcv， arp_rcv等）之前，将包先送到ptype_all抓包点。</p> <ul> <li>iptable/netfilter是在哪一层实现的？</li> </ul> <p>netfilter主要是在IP，ARP层实现的。如果配置过于复杂的规则，则会消耗过多CPU，加大网络延迟。</p> <ul> <li>tcpdump能否抓到被iptable封禁的包？</li> </ul> <p>tcpdump工作在设备层，而netfilter工作在IP/ARP层， 收包时，iptable封禁规则不影响tcpdump的抓包。 发包过程则相反，netfilter过滤后，tcpdump看不到被封禁的包。</p> <ul> <li>网络接收过程中的CPU开销如何查看</li> </ul> <p>在网络包的接收处理过程中，主要工作集中在硬中断和软中断上，二者的消耗都可以通过top命令查看。</p> <p>其中hi是cpu处理硬中断的开销，si是CPU处理软中断的开销，都是以百分比的形式来展示的。</p> <h2 id="内核是如何与用户进程协作的">内核是如何与用户进程协作的？</h2> <ul> <li>阻塞到底是怎么一回事？</li> </ul> <p>阻塞其实说的是进程因为等待某个事件而主动让出CPU挂起的操作。</p> <p>在网络IO中，当进程等待socket上的数据时，如果数据还没有到来，那就把当前进程状态从TASK_RUNNING 修改为 TASK_INTERRUPTIPLE, 然后主动让出CPU。 由调度器来调度下一个就绪的进程来执行。</p> <ul> <li>同步阻塞IO都需要哪些开销？ <ul> <li>从CPU开销角度看，一次同步阻塞IO将导致两次进程上下文切换开销。每一次切换大约花费3～5微妙。</li> <li>一个进程同时只能等待一条连接，如果有许多并发，则需要很多进程，每个进程都将占用大约几MB的内存。</li> </ul> </li> <li>多路复用epoll为什么就能提高网络性能？</li> </ul> <p>epoll高性能的最根本原因是极大程度地减少了无用的进程上下文切换，让进程更专注地处理网络请求。</p> <p>在内核的硬软中断上下文中，包从网卡接收过来进行处理，然后放到Socket的接收队列。再找到socket关联的epitem, 并把它添加到epoll对象的就绪链表中。</p> <p>在用户进程中，通过调用epoll_wait来查看就绪链表是否有事件到达，如果有，直接取走进行处理。处理完毕再次调用epoll_wait。在高并发的实践中，只要活儿足够多，epoll_wait根本不会让进程阻塞。</p> <p>直到epoll_wait里实在没活儿可干的时候才会让出CPU。这就是epoll高效的核心所在。</p> <ul> <li>为什么Redis的网络性能好？</li> </ul> <p>Redis在网络IO上表现非常突出，单进程的服务器在极限情况下可以达到10万的QPS。</p> <p>Redis的主要业务逻辑就是在本机内存上的数据结构的读写，单个请求处理起来很快。所以它把主服务端程序干脆做成了单线程的，这样省去了多线程之前协作的负担，也更大程度减少了线程切换。</p> <h2 id="内核是如何发送网络包的">内核是如何发送网络包的</h2> <ol> <li>用户进程send系统调用发送</li> <li>进入内核态，申请SKB，内存拷贝</li> <li>协议处理，传输层tcp头设置，滑动窗口管理 =》 网络层查找路由项，netfilter过滤，IP分片 =》 邻居子系统发送arp请求，获取目标MAC =》网络设备子系统，选择发送队列，skb入队</li> <li>进入驱动RingBuffer</li> <li>网卡实际发送</li> <li>网卡硬中断通知CPU发送完成</li> <li>触发软中断NET_RX_SOFTIRQ, 清理RingBuffer</li> </ol> <ul> <li>我们在监控内核发送数据消耗的CPU时，应该看sy还是si ?</li> </ul> <p>在网络包的发送过程中，用户进程（在内核态）完成了绝大部分工作，甚至连调用驱动的工作都干了。只当内核态进程被切走前才会发起软中断。 在发送过程中，绝大部分（90%）以上的开销都是在用户进程内核态消耗掉的。 只有一少部分情况才会触发软中断（NET_TX类型），由软中断ksoftirqd内核线程来发送。 所以，在监控网络IO对服务器造成的CPU开销的时候，不能仅看si, 而是应该把si, sy都考虑进来。</p> <ul> <li>在服务器上查看/proc/softirqs, 为什么NET_RX要比NET_TX大得多的多？ <ul> <li>原因1: 当数据发送完之后，触发的软中断是NET_RX_SOFTIRQ, 并不是NET_TX_SOFTIRQ.</li> <li>原因2: 收包时，都是要经过NET_RX软中断的，都走ksoftirqd内核线程。而发包时，绝大部分工作都是在用户进程内核态处理了，只有系统态配额用完才会发出NET_TX， 让软中断上。</li> </ul> </li> <li>发送网络数据的时候，都涉及哪些内存拷贝操作？ <ol> <li>将用户进程传递进来的buffer里的数据都拷贝到skb</li> <li>从传输层进入网络层的时候，进行浅拷贝，只拷贝skb描述符，所指向的数据复用。目的是网络对方没有回复ACK的时候，还可以重新发送，以实现TCP要求中的可靠传输。</li> <li>当网络层发现skb大于MTU时，进行分片，拷贝为多个小skb</li> </ol> </li> <li>零拷贝到底是怎么回事？为什么kafka的网络性能很突出？</li> </ul> <p>采用了sendfile系统调用来发送网络数据包，减少了内核态和用户态之间的频繁数据拷贝。</p> <p>而read + send系统调用发送文件过程如下：</p> <ol> <li>从硬盘DMA到内核态的page cache</li> <li>CPU拷贝page cache到用户内存</li> <li>cpu拷贝用户内存到socket发送缓冲区</li> <li>拷贝到RingBuffer</li> <li>DMA拷贝到网卡</li> </ol> <h2 id="深度理解本机网络io">深度理解本机网络IO</h2> <ul> <li>127.0.0.1本机网络IO需要经过网卡吗？</li> </ul> <p>不需要经过网卡，即使把网卡拔了，本机网络还是可以正常使用。</p> <ul> <li>数据包在内核中是什么走向，和外网发送相比流程上有什么差别？</li> </ul> <p>节约了驱动上的一些开销，发送数据不需要进RingBuffer的驱动队列，直接把skb传给接收协议栈（经过软中断）。但是 系统调用，协议栈（传输层，网络层等），设备子系统整个走了一遍。连“驱动”都走了（虽然回环设备是纯软件虚拟的）</p> <p>如果想在本机网络IO绕开协议栈的开销，可以使用eBPF, 使用eBPF的sockmap和sk redirect可以达到真正不走协议栈的目的。</p> <ul> <li>访问本机服务时，使用127.0.0.1能比使用其他IP更快吗？</li> </ul> <p>没有差别，都是走虚拟的环回设备lo， 这是因为内核在设置IP的时候，把所有的本机IP都初始化到local路由表里了。</p> <h2 id="深度理解tcp连接建立过程">深度理解TCP连接建立过程</h2> <ol> <li>服务端listen <ul> <li>申请并初始化接收队列，包括半连接队列和全连接队列</li> <li>全连接队列是1个链表，其最大长度min(listen时传入的backlog, net.core.somaxconn)</li> <li>半连接队列由于需要快速地查找，使用的是一个哈希表, 其最大长度是min(backlog, somaxconn, tcp_max_syn_backlog) + 1再向上取整到2的N次幂，但最小不能小于16</li> </ul> </li> <li>客户端connect <ul> <li>随机地从ip_local_port_range选择一个位置开始循环判断，选择可用的本地端口, 如果端口快用光了，内核大概率要循环多轮才能找到可用端口，这会导致connect系统调用的CPU开销上涨。如果端口查找失败，会报错“Cannot assign requested address”</li> <li>发出SYN握手请求</li> <li>启动重传定时器</li> </ul> </li> <li>服务端收到SYN握手请求 <ul> <li>发出SYC ACK</li> <li>进入半连接队列</li> <li>启动定时器</li> </ul> </li> <li>客户端收到SYN ACK <ul> <li>消除重传定时器</li> <li>设置为已连接</li> <li>发送ACK确认</li> </ul> </li> <li>服务端收到ACK <ul> <li>创建新sock</li> <li>从半连接队列删除</li> <li>加入全连接队列</li> </ul> </li> <li>服务端accept <ul> <li>从全连接队列取走socket</li> </ul> </li> </ol> <h3 id="握手异常总结">握手异常总结</h3> <ul> <li>如果端口不充足，处理方法有那么几个 <ul> <li>通过调整ip_local_port_range来尽量加大端口范围。</li> <li>尽量复用连接，使用长连接来削减频繁的握手处理</li> <li>有用但不太推荐的方法是开启tcp_tw_reuse和tcp_tw_recycle</li> </ul> </li> <li>半连接队列满，全连接队列满等导致丢包，应如何应对 <ul> <li>打开tcp_syncookies来防止过多请求打满半连接队列，包括SYN Flood攻击，来解决服务端因为半连接队列满而发生的丢包</li> <li>加大连接队列长度，可通过<code class="language-plaintext highlighter-rouge">ss -nlt</code>命令中输出的Send-Q来最终生效长度</li> <li>尽快调用accept, 应用程序应该尽快在握手成功后通过accept把新连接取走。</li> <li>尽早拒绝，例如将Redis，MySQL等服务器的内核参数tcp_abort_on_overflow设置为1，这是客户端会收到错误“connection reset by peer”</li> <li>用长连接代替短连接，减少过于频繁的三次握手</li> </ul> </li> </ul> <h2 id="一条tcp连接消耗多大内存">一条TCP连接消耗多大内存？</h2> <ul> <li>内核是如何管理内存的 <ol> <li>把所有内存条和CPU进行分组，组成node</li> <li>把每一个node划分成多个zone</li> <li>每个zone下都用伙伴系统来管理空闲页面</li> <li>提供slab分配器来管理各种内核对象， 每个slab缓存都是用来存储固定大小，甚至特定的一种内核对象。这样当一个对象释放后，另一个同类对象可以直接使用这块内存，几乎没有任何碎片，极大地提高了分配效率。</li> </ol> </li> <li>如何查看内核使用的内存信息 <ul> <li><code class="language-plaintext highlighter-rouge">sudo cat /proc/slabinfo</code> 可以看到所有的kmem cache</li> <li><code class="language-plaintext highlighter-rouge">sudo slabtop</code> 从大往小按照占用内存进行排列</li> </ul> </li> <li>服务器上一条ESTABLISH状态的空连接需要消耗多少内存？总共3.3KB左右 <ul> <li>struct socket_alloc, 大小约为0.62KB， slab缓存名是sock_inode_cache</li> <li>struct tcp_sock, 大小约为1.94KB， slab缓存名是tcp</li> <li>struct dentry, 大小约为0.19KB, slab缓存名是dentry</li> <li>struct file, 大小约为0.25KB, slab缓存名是flip</li> </ul> </li> <li>服务器上出现大量的TIME_WAIT, 内存开销会不会很大？ <ul> <li>一条TIME_WAIT状态的连接金占用0.4KB左右内存</li> <li>端口占用问题，可以考虑使用<code class="language-plaintext highlighter-rouge">tcp_max_tw_buckets</code>来限制TIME_WAIT连接总数，或者打开tcp_tw_recycle, tcp_tw_reuse来快速回收端口。</li> <li>使用长连接代替频繁的短连接</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="Linux"/><summary type="html"><![CDATA[内核是如何接收网络包的 当用户执行完recvfrom调用后，用户进程就通过系统调用进行到内核态工作了。如果接收队列没有数据，进程就进入睡眠状态被操作系统挂起。 数据帧从外部网络到达网卡 网卡把帧DMA到内存 硬中断通知CPU CPU响应硬中断，简单处理后发出软中断 ksoftirqd线程处理软中断，调用网卡驱动注册的poll函数开始收包 帧被从RingBuffer上摘下来保存为一个SKB 协议层开始处理网络帧，处理完后的数据data被放到Socket的接收队列中 内核唤醒用户进程]]></summary></entry><entry><title type="html">linux threads</title><link href="https://chenjun305.github.io/blog/2023/linux-threads/" rel="alternate" type="text/html" title="linux threads"/><published>2023-03-10T00:00:00+00:00</published><updated>2023-03-10T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/linux-threads</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/linux-threads/"><![CDATA[<h3 id="背景什么是smp">背景：什么是SMP？</h3> <p>对称多处理”（Symmetric multiprocessing）简称SMP，是一种多处理器的电脑硬件架构，指在一个计算机上汇集了一组处理器(多CPU)，各CPU之间共享内存子系统以及总线结构。它是相对非对称多处理技术而言的、应用十分广泛的并行技术。 在这种架构中，一台电脑不再由单个CPU组成，而同时由多个处理器运行操作系统的单一复本，并共享内存和一台计算机的其他资源。虽然同时使用多个CPU，但是从管理的角度来看，它们的表现就像一台单机一样。系统将任务队列对称地分布于多个CPU之上，从而极大地提高了整个系统的数据处理能力。所有的处理器都可以平等地访问内存、I/O和外部中断。在对称多处理系统中，系统资源被系统中所有CPU共享，工作负载能够均匀地分配到所有可用处理器之上。</p> <h3 id="基础知识线程和进程">基础知识：线程和进程</h3> <p>按照教科书上的定义，进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持SMP以及减小上下文切换开销。</p> <p>无论按照怎样的分法，一个进程至少需要一个线程作为它的指令执行体，进程管理着资源（比如cpu、内存、文件等等），而将线程分配到某个cpu上执行。一个进程当然可以拥有多个线程，此时，如果进程运行在SMP机器上，它就可以同时使用多个cpu来执行各个线程，达到最大程度的并行，以提高效率；同时，即使是在单cpu的机器上，采用多线程模型来设计程序，正如当年采用多进程模型代替单进程模型一样，使设计更简洁、功能更完备，程序的执行效率也更高，例如采用多个线程响应多个输入，而此时多线程模型所实现的功能实际上也可以用多进程模型来实现，而与后者相比，线程的上下文切换开销就比进程要小多了，从语义上来说，同时响应多个输入这样的功能，实际上就是共享了除cpu以外的所有资源的。</p> <p>针对线程模型的两大意义，分别开发出了核心级线程和用户级线程两种线程模型，分类的标准主要是线程的调度者在核内还是在核外。前者更利于并发使用多处理器的资源，而后者则更多考虑的是上下文切换开销。在目前的商用系统中，通常都将两者结合起来使用，既提供核心线程以满足smp系统的需要，也支持用线程库的方式在用户态实现另一套线程机制，此时一个核心线程同时成为多个用户态线程的调度者。正如很多技术一样，”混合”通常都能带来更高的效率，但同时也带来更大的实现难度，出于”简单”的设计思路，Linux从一开始就没有实现混合模型的计划，但它在实现上采用了另一种思路的”混合”。</p> <p>Linux内核只提供了轻量进程的支持，限制了更高效的线程模型的实现，但Linux着重优化了进程的调度开销，一定程度上也弥补了这一缺陷。目前最流行的线程机制LinuxThreads所采用的就是线程-进程”一对一”模型，调度交给核心，而在用户级实现一个包括信号处理在内的线程管理机制。</p> <h3 id="linux-24内核中的轻量进程实现">Linux 2.4内核中的轻量进程实现</h3> <p>最初的进程定义都包含程序、资源及其执行三部分，其中程序通常指代码，资源在操作系统层面上通常包括内存资源、IO资源、信号处理等部分，而程序的执行通常理解为执行上下文，包括对cpu的占用，后来发展为线程。在线程概念出现以前，为了减小进程切换的开销，操作系统设计者逐渐修正进程的概念，逐渐允许将进程所占有的资源从其主体剥离出来，允许某些进程共享一部分资源，例如文件、信号，数据内存，甚至代码，这就发展出轻量进程的概念。Linux内核在2.0.x版本就已经实现了轻量进程，应用程序可以通过一个统一的clone()系统调用接口，用不同的参数指定创建轻量进程还是普通进程。在内核中，clone()调用经过参数传递和解释后会调用do_fork()，这个核内函数同时也是fork()、vfork()系统调用的最终实现：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size)
</code></pre></div></div> <p>其中的clone_flags取自以下宏的”或”值：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#define CSIGNAL		    0x000000ff	/* signal mask to be sent at exit */
#define CLONE_VM		  0x00000100	/* set if VM shared between processes */
#define CLONE_FS      0x00000200	/* set if fs info shared between processes */
#define CLONE_FILES   0x00000400	/* set if open files shared between processes */
#define CLONE_SIGHAND	0x00000800	/* set if signal handlers and blocked signals shared*/
#define CLONE_PID		  0x00001000	/* set if pid shared */
#define CLONE_PTRACE	0x00002000	/* set if we want to let tracing continue on the child too *
#define CLONE_VFORK	  0x00004000	/* set if the parent wants the child to wake it up on mm_release */
#define CLONE_PARENT	0x00008000	/* set if we want to have the same parent as the cloner*/
#define CLONE_THREAD	0x00010000	/* Same thread group? */
#define CLONE_NEWNS	  0x00020000	/* New namespace group? */
#define CLONE_SIGNAL	(CLONE_SIGHAND | CLONE_THREAD)
</code></pre></div></div> <p>在do_fork()中，不同的clone_flags将导致不同的行为，对于LinuxThreads，它使用<code class="language-plaintext highlighter-rouge">（CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND）</code>参数来调用clone()创建”线程”，表示共享内存、共享文件系统访问计数、共享文件描述符表，以及共享信号处理方式。</p> <p>do_fork()中所做的工作很多，在此不详细描述。对于SMP系统，所有的进程fork出来后，都被分配到与父进程相同的cpu上，一直到该进程被调度时才会进行cpu选择。 尽管Linux支持轻量级进程，但并不能说它就支持核心级线程，因为Linux的”线程”和”进程”实际上处于一个调度层次，共享一个进程标识符空间，这种限制使得不可能在Linux上实现完全意义上的POSIX线程机制，因此众多的Linux线程库实现尝试都只能尽可能实现POSIX的绝大部分语义，并在功能上尽可能逼近。</p> <h3 id="linuxthreads的线程机制">LinuxThreads的线程机制</h3> <p>LinuxThreads是目前Linux平台上使用最为广泛的线程库，由Xavier Leroy (Xavier.Leroy@inria.fr) 负责开发完成，并已绑定在GLIBC中发行。它所实现的就是基于核心轻量级进程的”一对一”线程模型，一个线程实体对应一个核心轻量级进程，而线程之间的管理在核外函数库中实现.</p> <h4 id="1线程描述数据结构及实现限制">1.线程描述数据结构及实现限制</h4> <p>LinuxThreads定义了一个struct _pthread_descr_struct数据结构来描述线程，并使用全局数组变量__pthread_handles来描述和引用进程所辖线程。在__pthread_handles中的前两项，LinuxThreads定义了两个全局的系统线程：__pthread_initial_thread和__pthread_manager_thread，并用__pthread_main_thread表征__pthread_manager_thread的父线程（初始为__pthread_initial_thread）。</p> <p>struct _pthread_descr_struct是一个双环链表结构，__pthread_manager_thread所在的链表仅包括它一个元素，实际上，__pthread_manager_thread是一个特殊线程，LinuxThreads仅使用了其中的errno、p_pid、p_priority等三个域。而__pthread_main_thread所在的链则将进程中所有用户线程串在了一起。经过一系列pthread_create()之后形成的__pthread_handles数组将如下图所示：</p> <p>新创建的线程将首先在__pthread_handles数组中占据一项，然后通过数据结构中的链指针连入以__pthread_main_thread为首指针的链表中。这个链表的使用在介绍线程的创建和释放的时候将提到。</p> <p>LinuxThreads遵循POSIX1003.1c标准，其中对线程库的实现进行了一些范围限制，比如进程最大线程数，线程私有数据区大小等等。在LinuxThreads的实现中，基本遵循这些限制，但也进行了一定的改动，改动的趋势是放松或者说扩大这些限制，使编程更加方便。这些限定宏主要集中在sysdeps/unix/sysv/linux/bits/local_lim.h（不同平台使用的文件位置不同）中，包括如下几个：</p> <ul> <li>每进程的私有数据key数，POSIX定义_POSIX_THREAD_KEYS_MAX为128，LinuxThreads使用PTHREAD_KEYS_MAX，1024；</li> <li>私有数据释放时允许执行的操作数，LinuxThreads与POSIX一致，定义PTHREAD_DESTRUCTOR_ITERATIONS为4；</li> <li>每进程的线程数，POSIX定义为64，LinuxThreads增大到1024（PTHREAD_THREADS_MAX）；</li> <li>线程运行栈最小空间大小，POSIX未指定，LinuxThreads使用PTHREAD_STACK_MIN，16384（字节）。</li> </ul> <h4 id="2管理线程">2.管理线程</h4> <p>“一对一”模型的好处之一是线程的调度由核心完成了，而其他诸如线程取消、线程间的同步等工作，都是在核外线程库中完成的。在LinuxThreads中，专门为每一个进程构造了一个管理线程，负责处理线程相关的管理工作。当进程第一次调用pthread_create()创建一个线程的时候就会创建（__clone()）并启动管理线程。</p> <p>在一个进程空间内，管理线程与其他线程之间通过一对”管理管道（manager_pipe[2]）”来通讯，该管道在创建管理线程之前创建，在成功启动了管理线程之后，管理管道的读端和写端分别赋给两个全局变量__pthread_manager_reader和__pthread_manager_request，之后，每个用户线程都通过__pthread_manager_request向管理线程发请求，但管理线程本身并没有直接使用__pthread_manager_reader，管道的读端（manager_pipe[0]）是作为__clone()的参数之一传给管理线程的，管理线程的工作主要就是监听管道读端，并对从中取出的请求作出反应。</p> <p>创建管理线程的流程如下所示： （全局变量pthread_manager_request初值为-1）</p> <p>初始化结束后，在__pthread_manager_thread中记录了轻量级进程号以及核外分配和管理的线程id，2*PTHREAD_THREADS_MAX+1这个数值不会与任何常规用户线程id冲突。管理线程作为pthread_create()的调用者线程的子线程运行，而pthread_create()所创建的那个用户线程则是由管理线程来调用clone()创建，因此实际上是管理线程的子线程。（此处子线程的概念应该当作子进程来理解。）</p> <p>__pthread_manager()就是管理线程的主循环所在，在进行一系列初始化工作后，进入while(1)循环。在循环中，线程以2秒为timeout查询（__poll()）管理管道的读端。在处理请求前，检查其父线程（也就是创建manager的主线程）是否已退出，如果已退出就退出整个进程。如果有退出的子线程需要清理，则调用pthread_reap_children()清理。</p> <p>然后才是读取管道中的请求，根据请求类型执行相应操作（switch-case）。具体的请求处理，源码中比较清楚，这里就不赘述了。</p> <h4 id="3线程栈">3.线程栈</h4> <p>在LinuxThreads中，管理线程的栈和用户线程的栈是分离的，管理线程在进程堆中通过malloc()分配一个THREAD_MANAGER_STACK_SIZE字节的区域作为自己的运行栈。</p> <p>用户线程的栈分配办法随着体系结构的不同而不同，主要根据两个宏定义来区分，一个是NEED_SEPARATE_REGISTER_STACK，这个属性仅在IA64平台上使用；另一个是FLOATING_STACK宏，在i386等少数平台上使用，此时用户线程栈由系统决定具体位置并提供保护。与此同时，用户还可以通过线程属性结构来指定使用用户自定义的栈。因篇幅所限，这里只能分析i386平台所使用的两种栈组织方式：FLOATING_STACK方式和用户自定义方式。</p> <p>在FLOATING_STACK方式下，LinuxThreads利用mmap()从内核空间中分配8MB空间（i386系统缺省的最大栈空间大小，如果有运行限制（rlimit），则按照运行限制设置），使用mprotect()设置其中第一页为非访问区。该8M空间的功能分配如下图：</p> <p>低地址被保护的页面用来监测栈溢出。</p> <p>对于用户指定的栈，在按照指针对界后，设置线程栈顶，并计算出栈底，不做保护，正确性由用户自己保证。</p> <p>不论哪种组织方式，线程描述结构总是位于栈顶紧邻堆栈的位置。</p> <h4 id="4线程id和进程id">4.线程id和进程id</h4> <p>每个LinuxThreads线程都同时具有线程id和进程id，其中进程id就是内核所维护的进程号，而线程id则由LinuxThreads分配和维护。</p> <p>__pthread_initial_thread的线程id为PTHREAD_THREADS_MAX，__pthread_manager_thread的是2*PTHREAD_THREADS_MAX+1，第一个用户线程的线程id为PTHREAD_THREADS_MAX+2，此后第n个用户线程的线程id遵循以下公式：</p> <p>tid=n*PTHREAD_THREADS_MAX+n+1</p> <p>这种分配方式保证了进程中所有的线程（包括已经退出）都不会有t定义为无符号长整型（unsigned long int），也保证了有理由的运行时间内线程id不会重复。</p> <p>从线程id查找线程数据结构是在pthread_handle()函数中完成的，实际上只是将线程号按PTHREAD_THREADS_MAX取模，得到的就是该线程在__pthread_handles中的索引。</p> <h4 id="5线程的创建">5.线程的创建</h4> <p>在pthread_create()向管理线程发送REQ_CREATE请求之后，管理线程即调用pthread_handle_create()创建新线程。分配栈、设置thread属性后，以pthread_start_thread()为函数入口调用__clone()创建并启动新线程。pthread_start_thread()读取自身的进程id号存入线程描述结构中，并根据其中记录的调度方法配置调度。一切准备就绪后，再调用真正的线程执行函数，并在此函数返回后调用pthread_exit()清理现场。</p> <p>Linux内核并不支持真正意义上的线程，LinuxThreads是用与普通进程具有同样内核调度视图的轻量级进程来实现线程支持的。这些轻量级进程拥有独立的进程id，在进程调度、信号处理、IO等方面享有与普通进程一样的能力。在源码阅读者看来，就是Linux内核的clone()没有实现对CLONE_PID参数的支持。</p> <h4 id="6linuxthreads的不足">6.LinuxThreads的不足</h4> <p>由于Linux内核的限制以及实现难度等等原因，LinuxThreads并不是完全POSIX兼容的，在它的发行README中有说明。</p> <h5 id="1进程id问题">1)进程id问题</h5> <p>这个不足是最关键的不足，引起的原因牵涉到LinuxThreads的”一对一”模型。</p> <p>Linux内核并不支持真正意义上的线程，LinuxThreads是用与普通进程具有同样内核调度视图的轻量级进程来实现线程支持的。这些轻量级进程拥有独立的进程id，在进程调度、信号处理、IO等方面享有与普通进程一样的能力。在源码阅读者看来，就是Linux内核的clone()没有实现对CLONE_PID参数的支持。</p> <p>在内核do_fork()中对CLONE_PID的处理是这样的：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if (clone_flags &amp; CLONE_PID) {
if (current-&gt;pid)
goto fork_out;
}
</code></pre></div></div> <p>这段代码表明，目前的Linux内核仅在pid为0的时候认可CLONE_PID参数，实际上，仅在SMP初始化，手工创建进程的时候才会使用CLONE_PID参数。</p> <p>按照POSIX定义，同一进程的所有线程应该共享一个进程id和父进程id，这在目前的”一对一”模型下是无法实现的。</p> <h5 id="2信号处理问题">2)信号处理问题</h5> <p>由于异步信号是内核以进程为单位分发的，而LinuxThreads的每个线程对内核来说都是一个进程，且没有实现”线程组”，因此，某些语义不符合POSIX标准，比如没有实现向进程中所有线程发送信号，README对此作了说明。</p> <p>如果核心不提供实时信号，LinuxThreads将使用SIGUSR1和SIGUSR2作为内部使用的restart和cancel信号，这样应用程序就不能使用这两个原本为用户保留的信号了。在Linux kernel 2.1.60以后的版本都支持扩展的实时信号（从_SIGRTMIN到_SIGRTMAX），因此不存在这个问题。</p> <p>某些信号的缺省动作难以在现行体系上实现，比如SIGSTOP和SIGCONT，LinuxThreads只能将一个线程挂起，而无法挂起整个进程。</p> <h5 id="3线程总数问题">3)线程总数问题</h5> <p>LinuxThreads将每个进程的线程最大数目定义为1024，但实际上这个数值还受到整个系统的总进程数限制，这又是由于线程其实是核心进程。</p> <p>在kernel 2.4.x中，采用一套全新的总进程数计算方法，使得总进程数基本上仅受限于物理内存的大小，计算公式在kernel/fork.c的fork_init()函数中：</p> <p>max_threads = mempages / (THREAD_SIZE/PAGE_SIZE) / 8</p> <p>在i386上，THREAD_SIZE=2<em>PAGE_SIZE，PAGE_SIZE=2^12（4KB），mempages=物理内存大小/PAGE_SIZE，对于256M的内存的机器，mempages=256</em>2^20/2^12=256*2^8，此时最大线程数为4096。</p> <p>但为了保证每个用户（除了root）的进程总数不至于占用一半以上物理内存，fork_init()中继续指定：</p> <p>init_task.rlim[RLIMIT_NPROC].rlim_cur = max_threads/2; init_task.rlim[RLIMIT_NPROC].rlim_max = max_threads/2;</p> <p>这些进程数目的检查都在do_fork()中进行，因此，对于LinuxThreads来说，线程总数同时受这三个因素的限制。</p> <h5 id="4管理线程问题">4)管理线程问题</h5> <p>管理线程容易成为瓶颈，这是这种结构的通病；同时，管理线程又负责用户线程的清理工作，因此，尽管管理线程已经屏蔽了大部分的信号，但一旦管理线程死亡，用户线程就不得不手工清理了，而且用户线程并不知道管理线程的状态，之后的线程创建等请求将无人处理</p> <h5 id="5同步问题">5)同步问题</h5> <p>LinuxThreads中的线程同步很大程度上是建立在信号基础上的，这种通过内核复杂的信号处理机制的同步方式，效率一直是个问题。</p> <h5 id="6其他posix兼容性问题">6）其他POSIX兼容性问题</h5> <p>Linux中很多系统调用，按照语义都是与进程相关的，比如nice、setuid、setrlimit等，在目前的LinuxThreads中，这些调用都仅仅影响调用者线程。</p> <h5 id="7实时性问题">7）实时性问题</h5> <p>线程的引入有一定的实时性考虑，但LinuxThreads暂时不支持，比如调度选项，目前还没有实现。不仅LinuxThreads如此，标准的Linux在实时性上考虑都很少。</p>]]></content><author><name></name></author><category term="programming"/><category term="Linux"/><summary type="html"><![CDATA[背景：什么是SMP？ 对称多处理”（Symmetric multiprocessing）简称SMP，是一种多处理器的电脑硬件架构，指在一个计算机上汇集了一组处理器(多CPU)，各CPU之间共享内存子系统以及总线结构。它是相对非对称多处理技术而言的、应用十分广泛的并行技术。 在这种架构中，一台电脑不再由单个CPU组成，而同时由多个处理器运行操作系统的单一复本，并共享内存和一台计算机的其他资源。虽然同时使用多个CPU，但是从管理的角度来看，它们的表现就像一台单机一样。系统将任务队列对称地分布于多个CPU之上，从而极大地提高了整个系统的数据处理能力。所有的处理器都可以平等地访问内存、I/O和外部中断。在对称多处理系统中，系统资源被系统中所有CPU共享，工作负载能够均匀地分配到所有可用处理器之上。]]></summary></entry><entry><title type="html">linux kernel</title><link href="https://chenjun305.github.io/blog/2023/linux-kernel/" rel="alternate" type="text/html" title="linux kernel"/><published>2023-03-09T00:00:00+00:00</published><updated>2023-03-09T00:00:00+00:00</updated><id>https://chenjun305.github.io/blog/2023/linux-kernel</id><content type="html" xml:base="https://chenjun305.github.io/blog/2023/linux-kernel/"><![CDATA[<p>在纯技术层面上，内核是硬件与软件之间的一个中间层。其作用是将应用程序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。</p> <ul> <li>从应用程序的视角来看，内核可以被认为是一台增强的计算机，将计算机抽象到一个高层次上。</li> <li>当若干程序在同一系统中并发运行时，也可以将内核视为资源管理程序。</li> <li>另一种研究内核的视角是将内核视为库，其提供了一组面向系统的命令。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-overview-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-overview-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-overview-1400.webp"/> <img src="/assets/img/linux-overview.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Linux内核的高层次概述以及完整的Linux系统中的各个层次 </div> <h2 id="进程">进程</h2> <p>每个进程都在CPU的虚拟内存中分配地址空间。各个进程的地址空间是完全独立的，因此进程并不会意识到彼此的存在。从进程的角度来看，它会认为自己是系统中唯一的进程。如果进程想要彼此通信（例如交换数据），那么必须使用特定的内核机制。</p> <p>由于Linux是多任务系统，它支持（看上去）并发执行的若干进程。系统中同时真正在运行的进程数目最多不超过CPU数目，因此内核会按照短的时间间隔在不同的进程之间切换.</p> <ul> <li>内核借助于CPU的帮助，负责进程切换的技术细节。</li> <li> <p>内核还必须确定如何在现存进程之间共享CPU时间。确定哪个进程运行多长时间的过程称为调度。</p> </li> <li>init进程</li> </ul> <p>Linux对进程采用了一种层次系统，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程，该进程负责进一步的系统初始化操作，并显示登录提示符或图形登录界面。因此init是进程树的根，所有进程都直接或间接起源自该进程，可以用<code class="language-plaintext highlighter-rouge">pstree</code>命令输出进程树。其中init是一个树型结构的顶端，而树的分支不断向下扩展。</p> <p>操作系统中有两种创建新进程的机制，分别是fork和exec。</p> <ul> <li>fork</li> </ul> <p>fork可以创建当前进程的一个副本，父进程和子进程只有PID（进程ID）不同。在该系统调 用执行之后，系统中有两个进程，都执行同样的操作。父进程内存的内容将被复制，至少从程序的角 度来看是这样。Linux使用了一种众所周知的技术来使fork操作更高效，该技术称为写时复制（copy on write），主要的原理是将内存复制操作延迟到父进程或子进程向某内存页面写入数据之前，在只读访 问的情况下父进程和子进程可以共用同一内存页。</p> <ul> <li>exec</li> </ul> <p>exec将一个新程序加载到当前进程的内存中并执行。旧程序的内存页将刷出，其内容将替换 为新的数据。然后开始执行新程序。</p> <h2 id="进程间通信inter-process-communication-ipc">进程间通信（Inter-Process Communication, IPC）</h2> <h3 id="消息队列">消息队列</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-ipc-msg-queue-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-ipc-msg-queue-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-ipc-msg-queue-1400.webp"/> <img src="/assets/img/linux-ipc-msg-queue.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 消息队列的功能原理 </div> <p>产生消息并将其写到队列的进程通常称之为发送者，而一个或多个其他进程（逻辑上称之为接收者）则从队列获取信息。各个消息包含消息正文和一个（正）数，以便在消息队列内实现几种类型的消息。接收者可以根据该数字检索消息，例如，可以指定只接受编号1的消息，或接受编号不大于5的消息。在消息已经读取后，内核将其从队列删除。即使几个进程在同一信道上监听，每个消息仍然只能由一个进程读取。</p> <p>同一编号的消息按先进先出次序处理。放置在队列开始的消息将首先读取。但如果有选择地读取 消息，则先进先出次序就不再适用。</p> <p>相对于管道而言，更加适合进程之间较为频繁的交换数据。</p> <p>但是消息队列也有缺点，消息队列不适合比较大的数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</p> <p>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</p> <h3 id="共享内存">共享内存</h3> <p>消息队列的读取和写入的过程当中，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。</p> <p>现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。</p> <p>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</p> <p>共享内存更强大，但是也更复杂！</p> <h3 id="信号量">信号量</h3> <p>为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。</p> <p>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。</p> <h3 id="信号">信号</h3> <p>信号是进程间通信唯一的异步通信机制，一旦有信号产生，我们就必须执行下列操作之一：</p> <ul> <li>默认操作</li> <li>捕捉</li> <li>忽略</li> </ul> <p>kill命令根据PID向进程发送信号。信号通过-s sig指定，是一个正整数，最大长度取决于处理器类型。该命令有两种最常用的变体：一种是kill不指定信号，实际上是要求进程结束（进程可以忽略该信号）；另一种是kill -9，等价于在死刑批准上签字（导致某些进程死亡）。</p> <p>init进程属于特例。内核会忽略发送给该进程的SIGKILL信号。因为该进程对整个系统尤其重要，不能强制结束该进程，即使无意结束也不行。</p> <h3 id="管道">管道</h3> <p>shell用户可能比较熟悉管道，在命令行上可以如下使用：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ prog | ghostscript | lpr- 
</code></pre></div></div> <p>这里将一个进程的输出用作另一个进程的输入，管道负责数据的传输。顾名思义，管道是用于交换数据的连接。一个进程向管道的一端供给数据，另一个在管道另一端取出数据，供进一步处理。几个进程可以通过一系列管道连接起来。 在通过shell产生管道时，总有一个读进程和一个写进程。应用程序必须调用pipe系统调用产生管道。该调用返回两个文件描述符，分别用于管道的两端，即分别用于管道的读和写。</p> <h3 id="unix域协议">Unix域协议</h3> <p>Unix域协议是进程间通信 (IPC)的一种形式，可以通过与网络通信中使用的相同Socket API来访问它们。下图的左边表示使用socket写成的客户程序和服务器程序，它们在同一台主机上利用TCP/IP协议进行通信。下图的右边表示用socket写的利用Unix域协议进行通信的客户程序和服务器程序。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-ipc-socket-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-ipc-socket-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-ipc-socket-1400.webp"/> <img src="/assets/img/linux-ipc-socket.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 使用TCP/IP协议和Unix域协议的客户程序与服务器程序 </div> <h2 id="线程">线程</h2> <p>进程并不是内核支持的唯一一种程序执行形式。除了重量级进程（有时也称为UNIX进程）之外，还有一种形式是线程（有时也称为轻量级进程）。本质上一个进程可能由若干线程组成，这些线程共享同样的数据和资源，但可能执行程序中不同的代码路径。简而言之，进程可以看作一个正在执行的程序，而线程则是与主程序并行运行的程序函数或例程。</p> <p>Linux用clone方法创建线程。其工作方式类似于fork，但启用了精确的检查，以确认哪些资源与父进程共享、哪些资源为线程独立创建。</p> <h2 id="命名空间">命名空间</h2> <p>对命名空间的支持被集成到了许多子系统中。这使得不同的进程可以看到不同的系统视图。启用命名空间之后，以前的全局资源现在具有不同分组。每个命名空间可以包含一个特定的PID集合，或可以提供文件系统的不同视图，在某个命名空间中挂载的卷不会传播到其他命名空间中。</p> <p>命名空间很有用处。举例来说，该特性对虚拟主机供应商是有益的。他们不必再为每个用户准备一台物理计算机，而是通过称为容器的命名空间来建立系统的多个视图。从容器内部看来这是一个完整的Linux系统，而且与其他容器没有交互。容器是彼此分离的。每个容器实例看起来就像是运行Linux的一台计算机，但事实上一台物理机器可以同时运转许多这样的容器实例。这有助于更有效地使用资源。与完全的虚拟化解决方案（如KVM）相比，计算机上只需要运行一个内核来管理所有的容器。 并非内核的所有部分都完全支持命名空间.</p> <h2 id="地址空间与特权级别">地址空间与特权级别</h2> <p>由于内存区域是通过指针寻址，因此CPU的字长决定了所能管理的地址空间的最大长度。对32位系统，是2的32次方字节=4GiB，对更现代的64位处理器，可以管理2的64次方个字节。</p> <p>地址空间的最大长度与实际可用的物理内存数量无关，因此被称为虚拟地址空间。使用该术语的另一个理由是，从系统中每个进程的角度来看，地址空间中只有自身一个进程，而无法感知到其他进程的存在。</p> <p>Linux将虚拟地址空间划分为两个部分，分别称为内核空间和用户空间，如下图所示。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-virtual-address-space-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-virtual-address-space-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-virtual-address-space-1400.webp"/> <img src="/assets/img/linux-virtual-address-space.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> </div> </div> <div class="caption"> 虚拟地址空间的划分 </div> <p>系统中每个用户进程都有自身的虚拟地址范围，从0到TASK_SIZE。用户空间之上的区域保留给内核专用，用户进程不能访问。TASK_SIZE是一个特定于计算机体系结构的常数，把地址空间按给定比例划分为两部分。例如在IA-32系统中，地址空间在3 GiB处划分，因此每个进程的虚拟地址空间是3 GiB。由于虚拟地址空间的总长度是4 GiB，所以内核空间有1 GiB可用。尽管实际的数字依不同的计算机体系结构而不同，但一般概念都是相同的。</p> <p>这种划分与可用的内存数量无关。由于地址空间虚拟化的结果，每个用户进程都认为自身有3 GiB内存。各个系统进程的用户空间是完全彼此分离的。而虚拟地址空间顶部的内核空间总是同样的，无论当前执行的是哪个进程。</p> <p>注意，64位计算机的情况可能更复杂，因为它们在实际管理自身巨大的理论虚拟地址空间时，倾向于使用小于64的位数。实际使用的位数一般小于64位，如42位或47位。因此，地址空间中实际可寻址的部分小于理论长度。但无论如何，该值仍然大于计算机上实际可能的内存数量，因此是完全够用的。</p> <h4 id="特权级别">特权级别</h4> <p>内核把虚拟地址空间划分为两个部分，因此能够保护各个系统进程，使之彼此隔离。所有的现代CPU都提供了几种特权级别，进程可以驻留在某一特权级别。每个特权级别都有各种限制，例如对执行某些汇编语言指令或访问虚拟地址空间某一特定部分的限制。IA-32体系结构使用4种特权级别构成的系统，各级别可以看作是环。内环能够访问更多的功能，外环则较少，如图所示。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-cpu-priority-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-cpu-priority-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-cpu-priority-1400.webp"/> <img src="/assets/img/linux-cpu-priority.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 特权级别的环状系统 </div> <p>尽管英特尔处理器区分4种特权级别，但Linux只使用两种不同的状态：核心态和用户状态。两种状态的关键差别在于对高于TASK_SIZE的内存区域的访问。简而言之，在用户状态禁止访问内核空间。用户进程不能操作或读取内核空间中的数据，也无法执行内核空间中的代码。这是内核的专用领域。这种机制可防止进程无意间修改彼此的数据而造成相互干扰。</p> <p>从用户状态到核心态的切换通过系统调用的特定转换手段完成，且系统调用的执行因具体系统而不同。如果普通进程想要执行任何影响整个系统的操作（例如操作输入/输出装置），则只能借助于系统调用向内核发出请求。内核首先检查进程是否允许执行想要的操作，然后代表进程执行所需的操作，接下来返回到用户状态。</p> <p>除了代表用户程序执行代码之外，内核还可以由异步硬件中断激活，然后在中断上下文中运行。与在进程上下文中运行的主要区别是，在中断上下文中运行不能访问虚拟地址空间中的用户空间部分。因为中断可能随机发生，中断发生时可能是任一用户进程处于活动状态，由于该进程基本上与中断的原因无关，因此内核无权访问当前用户空间的内容。在中断上下文中运行时，内核必须比正常情况更加谨慎，例如，不能进入睡眠状态。在编写中断处理程序时需要特别注意这些，</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-cpu-execute-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-cpu-execute-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-cpu-execute-1400.webp"/> <img src="/assets/img/linux-cpu-execute.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 在核心态和用户状态执行。CPU大多数时间都在执行用户空间中的代码。当应用程序执行系统调用时，则切换到核心态，内核将完成其请求。在此期间，内核可以访问虚拟地址空间的用户部分。在系统调用完成之后，CPU切换回用户状态。硬件中断也会使CPU切换到核心态，这种情况下内核不能访问用户空间 </div> <p>除了普通进程，系统中还有内核线程在运行。内核线程也不与任何特定的用户空间进程相关联, 因此也无权处理用户空间。不过在其他许多方面，内核线程更像是普通的用户层应用程序。与在中断上下文运转的内核相比，内核线程可以进入睡眠状态，也可以像系统中的普通进程一样被调度器跟踪。内核线程可用于各种用途：从内存和块设备之间的数据同步，到帮助调度器在CPU上分配进程。</p> <p>在ps命令的输出中很容易识别内核线程，其名称都置于方括号内。在多处理器系统上，许多线程启动时指定了CPU，并限制只能在某个特定的CPU上运行。从内核线程名称之后的斜线和CPU编号可以看到这一点。</p> <h4 id="虚拟和物理地址空间">虚拟和物理地址空间</h4> <p>大多数情况下，单个虚拟地址空间就比系统中可用的物理内存要大。在每个进程都有自身的虚拟地址空间时，情况也不会有什么改善。因此内核和CPU必须考虑如何将实际可用的物理内存映射到虚拟地址空间的区域。可取的方法是用页表来为物理地址分配虚拟地址。虚拟地址关系到进程的用户空间和内核空间，而物理地址则用来寻址实际可用的内存。原理如图所示。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-memory-page-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-memory-page-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-memory-page-1400.webp"/> <img src="/assets/img/linux-memory-page.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 虚拟和物理地址 </div> <p>图中的箭头标明了虚拟地址空间中的页如何分配到物理内存页。例如，进程A的虚拟内存页1映射到物理内存页4，而进程B的虚拟内存页1映射到物理内存页5。由此可见，不同进程的同一虚拟地址实际上具有不同的含义。</p> <p>物理内存页经常称作页帧。相比之下，页则专指虚拟地址空间中的页。</p> <p>虚拟地址空间和物理内存之间的映射也使得进程之间的隔离有一点点松动。我们的例子即包含了一个由两个进程显式共享的页帧。进程A的页5和进程B的页1都指向物理页帧5。这种情况是可能的，因为两个虚拟地址空间中的页（虽然在不同的位置）可以映射到同一物理内存页。由于内核负责将虚拟地址空间映射到物理地址空间，因此可以决定哪些内存区域在进程之间共享，哪些不共享。</p> <p>上图表明并非虚拟地址空间的所有页都映射到某个页帧。这可能是因为页没有使用，或者是数据尚不需要使用而没有载入内存中。还可能是页已经换出到硬盘，将在需要时再换回内存。</p> <h2 id="页表">页表</h2> <p>用来将虚拟地址空间映射到物理地址空间的数据结构称为页表。实现两个地址空间的关联最容易的方法是使用数组，对虚拟地址空间中的每一页，都分配一个数组项。该数组项指向与之关联的页帧，但这个方法是不切实际的。</p> <p>因为虚拟地址空间的大部分区域都没有使用，因而也没有关联到页帧，那么就可以使用功能相同但内存用量少得多的模型：多级分页。</p> <p>Linux也采用了四级页表。</p> <p>页表的一个特色在于，对虚拟地址空间中不需要的区域，不必创建中间页目录或页表。与前述使用单个数组的方法相比，多级页表节省了大量内存。</p> <p>当然，该方法也有一个缺点。每次访问内存时，必须逐级访问多个数组才能将虚拟地址转换为物理地址。CPU试图用下面两种方法加速该过程。</p> <p>(1) CPU中有一个专门的部分称为MMU（Memory Management Unit，内存管理单元），该单元优化了内存访问操作。</p> <p>(2) 地址转换中出现最频繁的那些地址，保存到称为地址转换后备缓冲器（Translation Lookaside Buffer，TLB）的CPU高速缓存中。无需访问内存中的页表即可从高速缓存直接获得地址数据，因而大大加速了地址转换。</p> <h3 id="与cpu的交互">与CPU的交互</h3> <p>内核与体系结构无关的部分总是假定使用四级页表。对于只支持二级或三级页表的CPU来说，内核中体系结构相关的代码必须通过空页表对缺少的页表进行仿真。因此，内存管理代码剩余部分的实现是与CPU无关的。</p> <h3 id="内存映射">内存映射</h3> <p>内存映射是一种重要的抽象手段。在内核中大量使用，也可以用于用户应用程序。映射方法可以将任意来源的数据传输到进程的虚拟地址空间中。作为映射目标的地址空间区域，可以像普通内存那样用通常的方法访问。但任何修改都会自动传输到原数据源。这样就可以使用相同的函数来处理完全不同的目标对象。例如，文件的内容可以映射到内存中。处理只需读取相应的内存即可访问文件内容，或向内存写入数据来修改文件的内容。内核将保证任何修改都会自动同步到文件中。</p> <p>内核在实现设备驱动程序时直接使用了内存映射。外设的输入/输出可以映射到虚拟地址空间的区域中。对相关内存区域的读写会由系统重定向到设备，因而大大简化了驱动程序的实现。</p> <h2 id="物理内存的分配">物理内存的分配</h2> <p>在内核分配内存时，必须记录页帧的已分配或空闲状态，以免两个进程使用同样的内存区域。由于内存分配和释放非常频繁，内核还必须保证相关操作尽快完成。内核可以只分配完整的页帧。将内存划分为更小的部分的工作，则委托给用户空间中的标准库。标准库将来源于内核的页帧拆分为小的区域，并为进程分配内存。</p> <h3 id="伙伴系统">伙伴系统</h3> <p>内核中很多时候要求分配连续页。为快速检测内存中的连续区域，内核采用了一种古老而历经检验的技术：伙伴系统。</p> <p>系统中的空闲内存块总是两两分组，每组中的两个内存块称作伙伴。伙伴的分配可以是彼此独立的。但如果两个伙伴都是空闲的，内核会将其合并为一个更大的内存块，作为下一层次上某个内存块的伙伴。</p> <p>在应用程序释放内存时，内核可以直接检查地址，来判断是否能够创建一组伙伴，并合并为一个更大的内存块放回到伙伴列表中，这刚好是内存块分裂的逆过程。这提高了较大内存块可用的可能性。</p> <p>在系统长期运行时，服务器运行几个星期乃至几个月是很正常的，许多桌面系统也趋向于长期开机运行，那么会发生称为碎片的内存管理问题。频繁的分配和释放页帧可能导致一种情况：系统中有若干页帧是空闲的，但却散布在物理地址空间的各处。换句话说，系统中缺乏连续页帧组成的较大的内存块，而从性能上考虑，却又很需要使用较大的连续内存块。通过伙伴系统可以在某种程度上减少这种效应，但无法完全消除。如果在大块的连续内存中间刚好有一个页帧分配出去，很显然这两块空闲的内存是无法合并的。</p> <h3 id="slab缓存">slab缓存</h3> <p>内核本身经常需要比完整页帧小得多的内存块。由于内核无法使用标准库的函数，因而必须在伙伴系统基础上自行定义额外的内存管理层，将伙伴系统提供的页划分为更小的部分。该方法不仅可以分配内存，还为频繁使用的小对象实现了一个一般性的缓存——slab缓存。它可以用两种方法分配内存。</p> <p>(1) 对频繁使用的对象，内核定义了只包含了所需类型对象实例的缓存。每次需要某种对象时，可以从对应的缓存快速分配（使用后释放到缓存）。slab缓存自动维护与伙伴系统的交互，在缓存用尽时会请求新的页帧。</p> <p>(2) 对通常情况下小内存块的分配，内核针对不同大小的对象定义了一组slab缓存，可以像用户空间编程一样，用相同的函数访问这些缓存。不同之处是这些函数都增加了前缀k，表明是与内核相关联的：kmalloc和kfree。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-malloc-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-malloc-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-malloc-1400.webp"/> <img src="/assets/img/linux-malloc.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 页帧的分配由伙伴系统进行，而slab分配器则负责分配小内存以及提供一般性的内核缓存 </div> <h3 id="页面交换和页面回收">页面交换和页面回收</h3> <p>页面交换通过利用磁盘空间作为扩展内存，从而增大了可用的内存。在内核需要更多内存时，不经常使用的页可以写入硬盘。如果再需要访问相关数据，内核会将相应的页切换回内存。通过缺页异常机制，这种切换操作对应用程序是透明的。换出的页可以通过特别的页表项标识。在进程试图访问此类页帧时，CPU则启动一个可以被内核截取的缺页异常。此时内核可以将硬盘上的数据切换到内存中。接下来用户进程可以恢复运行。由于进程无法感知到缺页异常，所以页的换入和换出对进程是完全不可见的。</p> <p>页面回收用于将内存映射被修改的内容与底层的块设备同步，为此有时也简称为数据回写。数据刷出后，内核即可将页帧用于其他用途（类似于页面交换）。内核的数据结构包含了与此相关的所有信息，当再次需要该数据时，可根据相关信息从硬盘找到相应的数据并加载。</p> <h2 id="系统调用">系统调用</h2> <p>系统调用是用户进程与内核交互的经典方法。POSIX标准定义了许多系统调用，以及这些系统调用在所有遵从POSIX的系统包括Linux上的语义。传统的系统调用按不同类别分组，如下所示。</p> <blockquote> <p>可移植操作系统接口（英语：Portable Operating System Interface，缩写为POSIX）是IEEE为要在各种UNIX操作系统上运行软件，而定义API的一系列互相关联的标准的总称。此标准源于一个大约开始于1985年的项目。POSIX这个名称是由理查德·斯托曼（RMS）应IEEE的要求而提议的一个易于记忆的名称。它基本上是Portable Operating System Interface（可移植操作系统接口）的缩写，而X则表明其对Unix API的传承。</p> </blockquote> <ul> <li>进程管理：创建新进程，查询信息，调试。</li> <li>信号：发送信号，定时器以及相关处理机制。</li> <li>文件：创建、打开和关闭文件，从文件读取和向文件写入，查询信息和状态。</li> <li>目录和文件系统：创建、删除和重命名目录，查询信息，链接，变更目录。</li> <li>保护机制：读取和变更UID/GID，命名空间的处理。</li> <li>定时器函数：定时器函数和统计信息。</li> </ul> <p>所有这些函数都对内核提出了要求。这些函数不能以普通的用户库形式实现，因为需要特别的保护机制来保证系统稳定性或安全不受危及。此外许多调用依赖内核内部的结构或函数来得到所需的数据或结果，这也导致了无法在用户空间实现。在发出系统调用时，处理器必须改变特权级别，从用户状态切换到核心态。</p> <h2 id="设备驱动程序块设备和字符设备">设备驱动程序、块设备和字符设备</h2> <p>设备驱动程序用于与系统连接的输入/输出装置通信，如硬盘、软驱、各种接口、声卡等。按照经典的UNIX箴言“万物皆文件”（everything is a file），对外设的访问可利用<code class="language-plaintext highlighter-rouge">/dev</code>目录下的设备文件来完成，程序对设备的处理完全类似于常规的文件。设备驱动程序的任务在于支持应用程序经由设备文件与设备通信。换言之，使得能够按适当的方式在设备上读取/写入数据。</p> <p>外设可分为以下两类。</p> <p>(1) 字符设备：提供连续的数据流，应用程序可以顺序读取，通常不支持随机存取。相反，此类设备支持按字节/字符来读写数据。举例来说，调制解调器是典型的字符设备。</p> <p>(2) 块设备：应用程序可以随机访问设备数据，程序可自行确定读取数据的位置。硬盘是典型的块设备，应用程序可以寻址磁盘上的任何位置，并由此读取数据。此外，数据的读写只能以块（通常是512B）的倍数进行。与字符设备不同，块设备并不支持基于字符的寻址。</p> <p>编写块设备的驱动程序比字符设备要复杂得多，因为内核为提高系统性能广泛地使用了缓存机制。</p> <h2 id="网络">网络</h2> <p>网卡也可以通过设备驱动程序控制，但在内核中属于特殊状况，因为网卡不能利用设备文件访问。原因在于在网络通信期间，数据打包到了各种协议层中。在接收到数据时，内核必须针对各协议层的处理，对数据进行拆包与分析，然后才能将有效数据传递给应用程序。在发送数据时，内核必须首先根据各个协议层的要求打包数据，然后才能发送。</p> <p>为支持通过文件接口处理网络连接（按照应用程序的观点），Linux使用了源于BSD的套接字抽象。套接字可以看作应用程序、文件接口、内核的网络实现之间的代理。</p> <h2 id="文件系统">文件系统</h2> <p>Linux系统由数以千计乃至百万计的文件组成，其数据存储在硬盘或其他块设备（例如ZIP驱动、软驱、光盘等）。存储使用了层次式文件系统。文件系统使用目录结构组织存储的数据，并将其他元信息（例如所有者、访问权限等）与实际数据关联起来。Linux支持许多不同的文件系统：标准的Ext2和Ext3文件系统、ReiserFS、XFS、VFAT（为兼容DOS），还有很多其他文件系统。不同文件系统所基于的概念抽象，在某种程度上可以说是南辕北辙。Ext2基于inode，即它对每个文件都构造了一个单独的管理结构，称为inode，并存储到磁盘上。inode包含了文件所有的元信息，以及指向相关数据块的指针。目录可以表示为普通文件，其数据包括了指向目录下所有文件的inode的指针，因而层次结构得以建立。相比之下，ReiserFS广泛应用了树形结构来提供同样的功能。</p> <p>内核必须提供一个额外的软件层，将各种底层文件系统的具体特性与应用层（和内核自身）隔离开来。该软件层称为VFS（Virtual Filesystem或Virtual Filesystem Switch，虚拟文件系统或虚拟文件系统交换器）。VFS既是向下的接口（所有文件系统都必须实现该接口），同时也是向上的接口（用户进程通过系统调用最终能够访问文件系统功能）</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-file-system-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-file-system-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-file-system-1400.webp"/> <img src="/assets/img/linux-file-system.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 虚拟文件系统层、文件系统实现和块设备层之间的互操作 </div> <h2 id="虚拟文件系统">虚拟文件系统</h2> <p>为支持各种本机文件系统，且在同时允许访问其他操作系统的文件，Linux内核在用户进程（或C标准库）和文件系统实现之间引入了一个抽象层。该抽象层称之为虚拟文件系统（Virtual File System），简称VFS。 内核支持40多种文件系统，其来源各种各样：来自MS-DOS的FAT文件系统、UFS（Berkeley UNIX）、用于CD-ROM的iso9660、网络文件系统（如coda和NFS）和虚拟的文件系统（如proc）。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/linux-vfs-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/linux-vfs-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/linux-vfs-1400.webp"/> <img src="/assets/img/linux-vfs.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> 用作文件系统抽象的VFS层 </div> <h3 id="文件系统类型">文件系统类型</h3> <ul> <li>基于磁盘的文件系统（Disk-based Filesystem）是在非易失介质上存储文件的经典方法，用以 在多次会话之间保持文件的内容。</li> <li>虚拟文件系统（Virtual Filesystem）在内核中生成，是一种使用户应用程序与用户通信的方法。 proc文件系统是这一类的最佳示例。它不需要在任何种类的硬件设备上分配存储空间。相反，内核建 立了一个层次化的文件结构，其中的项包含了与系统特定部分相关的信息。</li> <li>网络文件系统（Network Filesystem）这种文件系统允许访问另一台计算机上的数据，该计算机通过网络连接到本地计算机.这意味着内核无需关注文件存取、数据组织和硬件通信的细节，这些由远程计算机的内核处理。对此类文件系统中文件的操作都通过网络连接进行。在进程向文件写数据时，数据使用特定的协议（由具体的网络文件系统决定）发送到远程计算机。接下来远程计算机负责存储传输的数据并通知发送者数据已经到达。 尽管如此，即使在内核处理网络文件系统时，仍然需要文件长度、文件在目录层次中的位置以及文件的其他重要信息。它必须也提供函数，使得用户进程能够执行通常的文件相关操作，如打开、读、删除等。由于VFS抽象层的存在，用户空间进程不会看到本地文件系统与网络文件系统之间的区别。</li> </ul> <h3 id="无持久存储的文件系统">无持久存储的文件系统</h3> <p>统上，文件系统用于在块设备上持久存储数据。但也可以使用文件系统来组织、提供或交换并不存储在块设备上的信息，这些信息可以由内核动态生成。</p> <h4 id="proc文件系统proc-filesystem">proc文件系统（proc filesystem）</h4> <p>它使得内核可以生成与系统的状态和配置有关的信息。该信息可以由用户和系统程序从普通文件读取，而无需专门的工具与内核通信。在某些情况下，一个简单的cat命令就足够了。数据不仅可以从内核读取，还可以通过向proc文件系统的文件写入字符串，来向内核发送数据。 该方法利用了一个虚拟文件系统“即时”产生文件信息。换句话说，只有发出读操作请求时，才会生成信息。对于此类文件系统，不需要专用的硬盘分区或其他块存储设备。</p> <ul> <li>特定于进程的数据</li> </ul> <p>每个系统进程，无论当前状态如何，都有一个对应的子目录（与其PID同名），包含了该进程的有关信息。顾名思义，进程数据系统（process data system，简称proc）的初衷就是传递进程数据。特定于进程的目录保存了哪些信息？简单的一个ls-l命令，就能看到一些信息：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd /proc/7748 
$ ls -l
</code></pre></div></div> <h4 id="sysfs文件系统">sysfs文件系统</h4> <p>sysfs是一个向用户空间导出内核对象的文件系统，它不仅提供了察看内核内部数据结构的能力，还可以修改这些数据结构。特别重要的是，该文件系统高度层次化的组织：sysfs的数据项来源于内核对象（kobject），而内核对象的层次化组织直接反映到了sysfs的目录布局中,由于系统的所有设备和总线都是通过kobject组织的，所以sysfs提供了系统的硬件拓扑的一种表示。 sysfs的标准装载点是/sys。</p> <h2 id="模块和热插拔">模块和热插拔</h2> <p>模块用于在运行时动态地向内核添加功能，如设备驱动程序、文件系统、网络协议等，实际上内核的任何子系统①几乎都可以模块化。这消除了宏内核与微内核相比一个重要的不利之处。</p> <p>模块还可以在运行时从内核卸载，这在开发新的内核组件时很有用。</p> <p>模块在本质上不过是普通的程序，只是在内核空间而不是用户空间执行而已。模块必须提供某些代码段②在模块初始化（和终止）时执行，以便向内核注册和注销模块。另外，模块代码与普通内核代码的权利（和义务）都是相同的，可以像编译到内核中的代码一样，访问内核中所有的函数和数据。</p> <p>对支持热插拔而言，模块在本质上是必需的。某些总线（例如，USB和FireWire）允许在系统运行时连接设备，而无需系统重启。在系统检测到新设备时，通过加载对应的模块，可以将必要的驱动程序自动添加到内核中。</p> <p>模块特性使得内核可以支持种类繁多的设备，而内核自身的大小却不会发生膨胀。在检测到连接的硬件后，只需要加载必要的模块，多余的驱动程序无需加入到内核。</p> <h2 id="缓存">缓存</h2> <p>内核使用缓存来改进系统性能。从低速的块设备读取的数据会暂时保持在内存中，即使数据在当时已经不再需要了。在应用程序下一次访问该数据时，它可以从访问速度较快的内存中读取，因而绕过了低速的块设备。由于内核是通过基于页的内存映射来实现访问块设备的，因此缓存也按页组织，也就是说整页都缓存起来，故称为页缓存（page cache）。</p> <h2 id="为什么内核是特别的">为什么内核是特别的</h2> <p>内核很神奇，但归根结底它只是一个大的C程序，带有一些汇编代码。是什么使得内核如此吸引人？原因有几个。首要一点在于，内核是由世界上最好的程序员编写的，源代码可以证实这一点。其结构良好，细节一丝不苟，巧妙的解决方案在代码中处处可见。一言以蔽之：内核应该是什么样子，它现在就是什么样子。但这并不意味着内核是应用教科书风格的程序设计方法学得出的产品。尽管内核采用了设计得非常干净的抽象，以保持代码的模块化和易管理性，但这一点与内核的其他方面混合起来，使得代码非常有趣和独特。在必要的情况下，内核会以上下文相关的方式重用比特位置，多次重载结构成员，从指针已经对齐的部分压榨出又一个存储位，自由地使用goto语句，还有很多其他东西，这些都会使任何强调结构的程序因痛苦而尖叫。</p>]]></content><author><name></name></author><category term="programming"/><category term="Linux"/><summary type="html"><![CDATA[在纯技术层面上，内核是硬件与软件之间的一个中间层。其作用是将应用程序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。]]></summary></entry></feed>